{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7c7a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Code is running!\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv, SoftmaxAggregation\n",
    "from torch_geometric.datasets import QM9\n",
    "import torch_geometric.nn as gnn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import GCL.augmentors as A\n",
    "#import edge_removing as A_alternate\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import RidgeClassifierCV, LogisticRegression, LinearRegression\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import timeit\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import argparse\n",
    "\n",
    "import copy\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7c66b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#record start time\n",
    "t_0 = timeit.default_timer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980440e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadfe1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Neural message passing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dbb0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.add_argument('--batch-size', type=int, default=100, metavar='batch_size',\n",
    "                    help='Input batch size for training (default: 20)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a803b3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.add_argument('--epochs', type=int, default=360, metavar='epochs',\n",
    "                    help='Number of epochs to train (default: 360)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f23150",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.add_argument('--lr', type=float, default=1e-4, metavar='lr',\n",
    "                    help='Initial learning rate [1e-5, 5e-4] (default: 1e-4)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a8267",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.add_argument('--lr-decay', type=float, default=0.6, metavar='lr_decay',\n",
    "                    help='Learning rate decay factor [.01, 1] (default: 0.6)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2d089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.add_argument('--num-filters', type=int, default=64, metavar='num_filters',\n",
    "                    help='Number of filters, default 64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48510ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.add_argument('--momentum', type=float, default=0.9, metavar='momentum',\n",
    "                    help='SGD momentum (default: 0.9)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cf6909",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e5019e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d77ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f88505",
   "metadata": {},
   "outputs": [],
   "source": [
    "qm9_index = {0: 'Dipole moment',\n",
    "1: 'Isotropic polarizability',\n",
    "2: 'Highest occupied molecular orbital energy',\n",
    "3: 'Lowest unoccupied molecular orbital energy',\n",
    "4: 'Gap between previous 2',\n",
    "5: 'Electronic spatial extent',\n",
    "6: 'Zero point vibrational energy',\n",
    "7: 'Internal energy at 0K',\n",
    "8: 'Internal energy at 298.15K',\n",
    "9: 'Enthalpy at 298.15K',\n",
    "10: 'Free energy at 298.15K',\n",
    "11: 'Heat capacity at 298.15K',\n",
    "12: 'Atomization energy at 0K',\n",
    "13: 'Atomization energy at 298.15K',\n",
    "14: 'Atomization enthalpy at 298.15K',\n",
    "15: 'Atomization free energy at 298.15K',\n",
    "16: 'Rotational constant A',\n",
    "17: 'Rotational constant B',\n",
    "18: 'Rotational constant C',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215aefd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {}\n",
    "\n",
    "# Augmentation selection\n",
    "augs = [#A.RWSampling(num_seeds=1000, walk_length=10),\n",
    "        #A.EdgeAttrMasking(pf=0.1),\n",
    "        #A.MarkovDiffusion(),\n",
    "        A.NodeDropping(pn=0.1),\n",
    "        A.NodeShuffling(),\n",
    "        #A.EdgeAdding(pe=0.1),\n",
    "        A.FeatureMasking(pf=0.1),\n",
    "        A.FeatureDropout(pf=0.1),\n",
    "        A.EdgeRemoving(pe=0.1)\n",
    "]\n",
    "\n",
    "augmentation = A.RandomChoice(augs, num_choices=2)\n",
    "\n",
    "val_aug = A.RandomChoice([], num_choices = 0)\n",
    "\n",
    "parameters['augmentation'] = augmentation\n",
    "\n",
    "# Hyperparameters\n",
    "parameters['n_epochs'] = args.epochs\n",
    "parameters['learning_rate'] = args.lr\n",
    "parameters['batch_size'] = args.batch_size\n",
    "parameters['model_size'] = args.num_filters\n",
    "parameters['learning_rate_decay'] = args.lr_decay\n",
    "parameters['momentum'] = args.momentum\n",
    "\n",
    "#parameters['n_epochs'] = 50\n",
    "#parameters['learning_rate'] = 3e-4\n",
    "#parameters['batch_size'] = 100\n",
    "#parameters['model_size'] = 64\n",
    "#parameters['learning_rate_decay'] = 0.6\n",
    "#parameters['momentum'] = 0.9\n",
    "\n",
    "# Supervised criterion\n",
    "metrics = [mean_squared_error, mean_absolute_error, r2_score]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737a490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dataset = QM9(root = 'data/')\n",
    "\n",
    "idx = []\n",
    "for i in range(130831):\n",
    "    if i != 474 and i != 14240:\n",
    "        idx += [i]\n",
    "whole_dataset = whole_dataset.index_select(idx= idx)\n",
    "\n",
    "# Eric outlier removal\n",
    "\n",
    "n = whole_dataset.len()\n",
    "tr_n = 0.5  # Number of QM9 to use as training data\n",
    "\n",
    "all_inds = range(n-2)\n",
    "tr_inds, val_inds = train_test_split(all_inds, train_size = tr_n)\n",
    "train_set = torch.utils.data.Subset(whole_dataset, tr_inds)\n",
    "val_set = torch.utils.data.Subset(whole_dataset, val_inds)\n",
    "\n",
    "train_loader = torch_geometric.loader.DataLoader(train_set, batch_size = parameters['batch_size'],\n",
    "                                                shuffle = True, num_workers = 2,)\n",
    "\n",
    "big_train_loader = torch_geometric.loader.DataLoader(train_set, batch_size = int(1e9),\n",
    "                                                shuffle = True, num_workers = 2,)\n",
    "\n",
    "val_loader = torch_geometric.loader.DataLoader(val_set, batch_size=int(1e9), # I am using this to get a random subset of the val set\n",
    "                                            shuffle=True, num_workers=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848bfd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, model_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rep_dim = model_size\n",
    "        self.emb_dim = model_size * 2\n",
    "        \n",
    "        # Data under graph\n",
    "        self.conv1 = GCNConv(whole_dataset.num_node_features, self.rep_dim // 2)\n",
    "        self.conv1.aggr = SoftmaxAggregation(learn=True)\n",
    "        self.bn1 = nn.BatchNorm1d(self.rep_dim // 2)\n",
    "        self.a1 = nn.LeakyReLU(0.02)\n",
    "        \n",
    "        self.conv2 = GCNConv(self.rep_dim // 2, self.rep_dim) # To Rep Space\n",
    "        self.conv2.aggr = SoftmaxAggregation(learn=True)\n",
    "        self.bn2 = nn.BatchNorm1d(self.rep_dim)\n",
    "        \n",
    "        # Projection to representation\n",
    "        self.mpool1 = gnn.global_mean_pool\n",
    "        #self.fc1 = nn.Linear(self.rep_dim, self.rep_dim)\n",
    "        \n",
    "        # Graph 2\n",
    "        self.conv3 = GCNConv(self.rep_dim, self.rep_dim * 2) # To Emb Space\n",
    "        self.bn3 = nn.BatchNorm1d(self.rep_dim * 2)\n",
    "        \n",
    "        # Projection to embedding\n",
    "        #self.mpool2 = gnn.global_mean_pool\n",
    "        #self.fc2 = nn.Linear(self.emb_dim, self.emb_dim) # Linear to rep?\n",
    "        \n",
    "    def forward(self, data, binds):\n",
    "        x = data[0].float().to(device)\n",
    "        edge_index = data[1].to(device)\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.a1(self.bn1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.bn2(self.conv2(x, edge_index))\n",
    "        \n",
    "        x_rep = self.mpool1(x, binds)\n",
    "        \n",
    "        x_emb = self.conv3(x, edge_index)\n",
    "        return x_rep, x_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc1630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def off_diagonal(x):\n",
    "    n, m = x.shape\n",
    "    assert n == m\n",
    "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
    "\n",
    "def VicRegLoss(x, y):\n",
    "    # https://github.com/facebookresearch/vicreg/blob/4e12602fd495af83efd1631fbe82523e6db092e0/main_vicreg.py#L184\n",
    "    # x, y are output of projector(backbone(x and y))\n",
    "    \n",
    "    # These are the default params used in natural image vicreg\n",
    "    sim_coeff = 25\n",
    "    std_coeff = 25\n",
    "    cov_coeff = 1\n",
    "    \n",
    "    \n",
    "    repr_loss = F.mse_loss(x, y)\n",
    "\n",
    "    x = x - x.mean(dim=0)\n",
    "    y = y - y.mean(dim=0)\n",
    "\n",
    "    std_x = torch.sqrt(x.var(dim=0) + 0.0001)\n",
    "    std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
    "    std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
    "\n",
    "    cov_x = (x.T @ x) / (parameters['batch_size'] - 1)\n",
    "    cov_y = (y.T @ y) / (parameters['batch_size'] - 1)\n",
    "    cov_loss = off_diagonal(cov_x).pow_(2).sum().div(\n",
    "        x.shape[1]\n",
    "    ) + off_diagonal(cov_y).pow_(2).sum().div(x.shape[1])\n",
    "    \n",
    "    # self.num_features -> rep_dim?\n",
    "    loss = (\n",
    "        sim_coeff * repr_loss\n",
    "        + std_coeff * std_loss\n",
    "        + cov_coeff * cov_loss\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train(parameters):\n",
    "    \n",
    "    device = 'cuda'\n",
    "\n",
    "    model = GCN(parameters['model_size']).to(device)\n",
    "    n_epochs = parameters['n_epochs']\n",
    "    aug = parameters['augmentation']\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=parameters['learning_rate'], weight_decay=parameters['learning_rate_decay'])\n",
    "\n",
    "    tr_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(0,n_epochs+1):\n",
    "        epoch_losses = []\n",
    "        for batch in train_loader:\n",
    "            #print('training batch')\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            batch_inds = batch.batch.to(device)\n",
    "\n",
    "            # batch of graphs has edge attribs, node attribs - (n_nodes, n_features+1) -> concat (n_nodes, attrib1)\n",
    "            batch.x = batch.x.float()#.to(device)\n",
    "            \n",
    "            #print('batch.x.shape', batch.x.shape)\n",
    "\n",
    "            # Barlow - get 2 random views of batch\n",
    "            b1 = aug(batch.x, batch.edge_index, batch.edge_attr)\n",
    "            b2 = aug(batch.x, batch.edge_index, batch.edge_attr)\n",
    "\n",
    "            # Embed each batch (ignoring representations)\n",
    "            r1, e1 = model(b1, batch_inds)\n",
    "            r2, e2 = model(b2, batch_inds)\n",
    "            \n",
    "            #print('calcing loss')\n",
    "\n",
    "            loss = VicRegLoss(e1, e2)\n",
    "            #print('backward loss')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print('succesful backward')\n",
    "\n",
    "            epoch_losses.append(loss.data.item())\n",
    "        \n",
    "        #print('epoch train loss', sum(epoch_losses) / len(epoch_losses))\n",
    "        tr_losses.append(sum(epoch_losses) / len(epoch_losses))\n",
    "        print(\"Epoch \", epoch, \"training loss: \", sum(epoch_losses) / len(epoch_losses))\n",
    "        \n",
    "        # VicReg Validation Loss\n",
    "        if True:\n",
    "            val_loss = []\n",
    "            for batch in val_loader:\n",
    "                with torch.no_grad():\n",
    "                    #print('calcuing validation')\n",
    "                    # VicReg validation loss\n",
    "                    b1 = aug(batch.x, batch.edge_index, batch.edge_attr)\n",
    "                    b2 = aug(batch.x, batch.edge_index, batch.edge_attr)\n",
    "                    r1, e1 = model(b1, batch.batch.to(device))\n",
    "                    r2, e2 = model(b2, batch.batch.to(device))\n",
    "\n",
    "                    val_loss.append(VicRegLoss(e1, e2).item())\n",
    "\n",
    "            val_losses.append(torch.mean(torch.FloatTensor(val_loss)))\n",
    "            #print('successful validation')\n",
    "        print(\"Epoch \", epoch, \"validation loss: \", torch.mean(torch.FloatTensor(val_loss)))\n",
    "    return model, tr_losses, val_losses\n",
    "\n",
    "def test(model, big_train_loader, val_loader, parameters):\n",
    "    print('entering test, ')\n",
    "    # Downstream supervised loss      \n",
    "    scores = []\n",
    "    for batch in big_train_loader: # take entire train set\n",
    "        with torch.no_grad():\n",
    "            # Embed training set under model\n",
    "            rep_tr, _ = model(val_aug(batch.x, batch.edge_index, batch.edge_attr), batch.batch.to(device))\n",
    "\n",
    "            for i, val_batch in enumerate(big_val_loader):\n",
    "                #print('doing a batch')\n",
    "                # Embed validation set under model\n",
    "                rep_val, _ = model(val_aug(val_batch.x, val_batch.edge_index, val_batch.edge_attr), val_batch.batch.to(device))\n",
    "\n",
    "                # For each task in QM9\n",
    "                for tar_ind in range(batch.y.shape[1]):\n",
    "                    # Fit a model on model representation of train set\n",
    "                    lm = LinearRegression().fit(rep_tr.cpu(), batch.y[:,tar_ind])\n",
    "                    # Test the model on model repersentation of val set\n",
    "                    tar_yhat = lm.predict(rep_val.cpu())\n",
    "                    mse_met = mean_squared_error(val_batch.y[:,tar_ind], tar_yhat).item()\n",
    "                    r2_met = r2_score(val_batch.y[:,tar_ind], tar_yhat)\n",
    "                    scores.append(mse_met)\n",
    "                    print(\"Linear model loss for \", qm9_index[tar_ind], \": \", mse_met)\n",
    "                    print(\"R2 score for \", qm9_index[tar_ind], \": \", r2_met)\n",
    "                if i==0:\n",
    "                    break # Only want first batch, please\n",
    "                    \n",
    "            #print('left the first test one')\n",
    "                    \n",
    "    return scores\n",
    "\n",
    "def transfer(model, val_loader, parameters):\n",
    "    # Transfer a model trained under the supervised paradigm    \n",
    "    # Need to get training set embeddings:\n",
    "    train_batch = next(iter(big_train_loader))\n",
    "    with torch.no_grad():\n",
    "        tr_emb, _ = model([train_batch.x.float().to(device), train_batch.edge_index, train_batch.edge_attr], train_batch.batch.to(device))\n",
    "        #print('train embeddings', tr_emb.shape)\n",
    "        tr_emb = tr_emb.cpu()\n",
    "    \n",
    "    val_batch = next(iter(val_loader))\n",
    "\n",
    "    batch_inds = val_batch.batch.to(device)\n",
    "    val_batch.x = val_batch.x.float()#.to(device)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_emb, _ = model([val_batch.x, val_batch.edge_index, val_batch.edge_attr], batch_inds)\n",
    "        #print('batch embeding:', val_emb.shape)\n",
    "        val_emb = val_emb.cpu()\n",
    "\n",
    "    scoremat = torch.zeros((len(qm9_index.keys()), len(metrics)))\n",
    "    for task in qm9_index.keys():\n",
    "        linear_classifier = LinearRegression().fit(tr_emb, train_batch.y[:,task])\n",
    "        yhat = linear_classifier.predict(val_emb)\n",
    "        for meti, metric in enumerate(metrics):\n",
    "            met = metric(yhat, val_batch.y[:,task])\n",
    "            scoremat[task, meti] = met.astype(np.float64)\n",
    "            \n",
    "    print('Returning transfer scores', scoremat.shape)\n",
    "    return scoremat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85b9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr_str = 'lr' + str(parameters['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789127a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a50968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af424a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_trials = 3\n",
    "for i in range(1,n_trials):\n",
    "    model, tr_loss, val_loss = train(parameters)\n",
    "    \n",
    "    print(tr_loss, val_loss)\n",
    "    plt.plot(tr_loss, label = 'tr')\n",
    "    plt.plot(val_loss, label = 'val')\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.show()\n",
    "    plt.savefig('/home/ewvertina/Molecular_modelling/heatmap_results/lr' + str(parameters['learning_rate']) + '_epo' + str(parameters['n_epochs']) + '_bs' + str(parameters['batch_size']) + '_nfilt' + str(parameters['model_size']) + '_lrd' + str(parameters['learning_rate_decay']) + '_vicreg' + str(i) + '.png')\n",
    "    scores = transfer(model, val_loader, parameters)\n",
    "    torch.save(scores, '/home/ewvertina/Molecular_modelling/heatmap_results/lr' + str(parameters['learning_rate']) + '_epo' + str(parameters['n_epochs']) + '_bs' + str(parameters['batch_size']) + '_nfilt' + str(parameters['model_size']) + '_lrd' + str(parameters['learning_rate_decay']) + '_vicreg' + str(i) + '.pt')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d24b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(scores, '/home/ewvertina/Molecular_modelling/heatmap_results/vicreg1.pt')\n",
    "#torch.save(scores, '/home/ewvertina/Molecular_modelling/heatmap_results/lr' + str(parameters['learning_rate']) + '_epo' + str(parameters['n_epochs']) + '_bs' + str(parameters['batch_size']) + '_nfilt' + str(parameters['model_size']) + '_lrd' + str(parameters['learning_rate_decay']) + '_vicreg' + str(i) + '.pt')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189747f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plt.plot(tr_loss, label = 'tr')\n",
    "#plt.plot(val_loss, label = 'val')\n",
    "#plt.legend(loc = 'best')\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e0a1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(scores)\n",
    "print(scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790383d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for met, row in zip(metrics, scores.T):\n",
    "    #print(met, row)\n",
    "    for i, item in enumerate(row):\n",
    "        print(met, qm9_index[i], item)\n",
    "        \n",
    "#torch.save(scores, '/home/ewvertina/Molecular_modelling/Vicreg_score_demo/vicreg_score_demo_lr' + str(parameters['learning_rate']) + '_epo' + str(parameters['n_epochs']) + '_bs' + str(parameters['batch_size']) + '_nfilt' + str(parameters['model_size']) + '_lrd' + str(parameters['learning_rate_decay']) + '_vicreg' + str(i) + '.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c803c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb51854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6ad028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record end time\n",
    "t_1 = timeit.default_timer()\n",
    " \n",
    "# calculate elapsed time\n",
    "elapsed_time = round((t_1 - t_0) , 1)\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "elapsed_time_minutes = round((elapsed_time/60), 2)\n",
    "print(f\"Elapsed time: {elapsed_time_minutes} minutes\")\n",
    "elapsed_time_hours = round((elapsed_time/3600), 2)\n",
    "print(f\"Elapsed time: {elapsed_time_hours} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dde6b41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7645c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04582664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
