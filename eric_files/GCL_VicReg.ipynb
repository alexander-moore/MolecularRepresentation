{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "29e6fa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code is running!\n"
     ]
    }
   ],
   "source": [
    "# https://arxiv.org/abs/1610.02415\n",
    "\n",
    "# https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html\n",
    "print(\"Code is running!\")\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.nn as gnn\n",
    "\n",
    "from torch_geometric.datasets import QM9\n",
    "import GCL.augmentors\n",
    "import GCL.augmentors as A\n",
    "import edge_removing as A_alternate\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import RidgeClassifierCV, LogisticRegression, LinearRegression\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "from rdkit.Chem import PeriodicTable\n",
    "from rdkit import Chem\n",
    "from xenonpy.datatools import preset\n",
    "from xenonpy.descriptor import Compositions\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from matplotlib.pylab import plt\n",
    "from numpy import arange\n",
    "import math\n",
    "import timeit\n",
    "import os\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e72ca970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following are needed to use PyTorch Lightning\n",
    "from functools import partial\n",
    "from typing import Sequence, Tuple, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as VisionF\n",
    "from pytorch_lightning import Callback, LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.functional import accuracy\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.models.resnet import resnet18\n",
    "from torchvision.utils import make_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be3d6a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#record start time\n",
    "t_0 = timeit.default_timer()\n",
    "# call function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b39d0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"QM9\"\n",
    "tr_batch_size = 1000\n",
    "val_batch_size = 200\n",
    "test_batch_size = 100\n",
    "tr_ratio = 0.9\n",
    "val_ratio = 0.09\n",
    "test_ratio = 0.01\n",
    "num_workers = 2\n",
    "shuffle = True\n",
    "qm9_index_list = ['Dipole_moment', \n",
    "                  'Isotropic_polarizability',\n",
    "                  'Highest_occupied_molecular_orbital_energy',\n",
    "                  'Lowest_unoccupied_molecular_orbital_energy',\n",
    "                  'Gap_between_previous_2',\n",
    "                  'Electronic_spatial_extent',\n",
    "                  'Zero_point_vibrational_energy',\n",
    "                  'Internal_energy_at_0K',\n",
    "                  'Internal_energy_at_298.15K',\n",
    "                  'Enthalpy_at_298.15K',\n",
    "                  'Free_energy_at_298.15K',\n",
    "                  'Heat_capacity_at_298.15K',\n",
    "                  'Atomization_energy_at_0K',\n",
    "                  'Atomization_energy_at_298.15K',\n",
    "                  'Atomization_enthalpy_at_298.15K',\n",
    "                  'Atomization_free_energy_at_298.15K',\n",
    "                  'Rotational_constant_A',\n",
    "                  'Rotational_constant_B',\n",
    "                  'Rotational_constant_C']\n",
    "\n",
    "parameters = {}\n",
    "parameters['tr_batch_size'] = tr_batch_size\n",
    "\n",
    "parameters_used = {}\n",
    "parameters_used['dataset'] = dataset\n",
    "parameters_used['tr_batch_size'] = tr_batch_size\n",
    "parameters_used['val_batch_size'] = val_batch_size\n",
    "parameters_used['test_batch_size'] = test_batch_size\n",
    "parameters_used['tr_ratio'] = tr_ratio\n",
    "parameters_used['val_ratio'] = val_ratio\n",
    "parameters_used['test_ratio'] = test_ratio\n",
    "parameters_used['num_workers'] = num_workers\n",
    "parameters_used['shuffle'] = shuffle\n",
    "parameters_used['target_properties'] = qm9_index_list\n",
    "\n",
    "periodic_table = Chem.GetPeriodicTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa936b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set:  117747\n",
      "Size of validation set:  11774\n",
      "Size of test set:  1310\n"
     ]
    }
   ],
   "source": [
    "whole_dataset = QM9(root = 'data/')\n",
    "\n",
    "#print(whole_dataset.get_summary())\n",
    "#print(dir(whole_dataset))\n",
    "#print(whole_dataset.len())\n",
    "\n",
    "\n",
    "\n",
    "n = whole_dataset.len()\n",
    "tr_n = math.floor(tr_ratio*n) # Number of QM9 to use as training data\n",
    "val_n = math.floor(val_ratio*n)\n",
    "\n",
    "\n",
    "\n",
    "all_inds = range(n)\n",
    "#print(\"all_inds: \", all_inds)\n",
    "tr_inds, val_inds = train_test_split(all_inds, train_size = tr_n, random_state = 24)\n",
    "val_test_inds = range(n - tr_n)\n",
    "#print(\"val_test_inds: \", val_test_inds)\n",
    "val_inds, test_inds = train_test_split(val_test_inds, train_size = val_n, random_state = 24)\n",
    "\n",
    "\n",
    "print(\"Size of training set: \", len(tr_inds))\n",
    "print(\"Size of validation set: \", len(val_inds))\n",
    "print(\"Size of test set: \", len(test_inds))\n",
    "#print(type(tr_inds), type(tr_inds[0]))\n",
    "\n",
    "\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(tr_inds)\n",
    "val_sampler = torch.utils.data.SubsetRandomSampler(val_inds)\n",
    "test_sampler = torch.utils.data.SubsetRandomSampler(test_inds)\n",
    "\n",
    "\n",
    "# We need to make a train and validation set since QM9 does not provide them\n",
    "train_set = torch.utils.data.Subset(whole_dataset, tr_inds)\n",
    "val_set = torch.utils.data.Subset(whole_dataset, val_inds)\n",
    "test_set = torch.utils.data.Subset(whole_dataset, test_inds)\n",
    "\n",
    "train_loader = torch_geometric.loader.DataLoader(train_set, batch_size = tr_batch_size,\n",
    "                                                shuffle = shuffle, num_workers = num_workers)\n",
    "                                                #sampler = train_sampler)\n",
    "\n",
    "val_loader = torch_geometric.loader.DataLoader(val_set, batch_size=val_batch_size,\n",
    "                                            shuffle=shuffle, num_workers=num_workers, drop_last=True)\n",
    "                                              #sampler = val_sampler)\n",
    "test_loader = torch_geometric.loader.DataLoader(test_set, batch_size=test_batch_size,\n",
    "                                            shuffle=shuffle, num_workers=num_workers)\n",
    "                                              #sampler = val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e6dc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51130aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph_chem_formulae_dictionaries = pd.DataFrame()\n",
    "tr_mol_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dcc37f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "qm9_index = {0: 'Dipole moment',\n",
    "1: 'Isotropic polarizability',\n",
    "2: 'Highest occupied molecular orbital energy',\n",
    "3: 'Lowest unoccupied molecular orbital energy',\n",
    "4: 'Gap between previous 2',\n",
    "5: 'Electronic spatial extent',\n",
    "6: 'Zero point vibrational energy',\n",
    "7: 'Internal energy at 0K',\n",
    "8: 'Internal energy at 298.15K',\n",
    "9: 'Enthalpy at 298.15K',\n",
    "10: 'Free energy at 298.15K',\n",
    "11: 'Heat capacity at 298.15K',\n",
    "12: 'Atomization energy at 0K',\n",
    "13: 'Atomization energy at 298.15K',\n",
    "14: 'Atomization enthalpy at 298.15K',\n",
    "15: 'Atomization free energy at 298.15K',\n",
    "16: 'Rotational constant A',\n",
    "17: 'Rotational constant B',\n",
    "18: 'Rotational constant C'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8887ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_index = {0: 'H atom?',\n",
    "1: 'C atom?',\n",
    "2: 'N atom?',\n",
    "3: 'O atom?',\n",
    "4: 'F atom?',\n",
    "5: 'atomic_number',\n",
    "6: 'aromatic',\n",
    "7: 'sp1',\n",
    "8: 'sp2',\n",
    "9: 'sp3',\n",
    "10: 'num_hs'}\n",
    "x_index_list = ['H atom?', \n",
    "                'C atom?', \n",
    "                'N atom?', \n",
    "                'O atom?', \n",
    "                'F atom?', \n",
    "                'atomic_number', 'aromatic', \n",
    "                'sp1',\n",
    "                'sp2',\n",
    "                'sp3',\n",
    "                'num_hs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5fc22a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def off_diagonal(x):\n",
    "    n, m = x.shape\n",
    "    assert n == m\n",
    "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
    "\n",
    "def VicRegLoss(x, y):\n",
    "    # https://github.com/facebookresearch/vicreg/blob/4e12602fd495af83efd1631fbe82523e6db092e0/main_vicreg.py#L184\n",
    "    # x, y are output of projector(backbone(x and y))\n",
    "    repr_loss = F.mse_loss(x, y)\n",
    "\n",
    "    x = x - x.mean(dim=0)\n",
    "    y = y - y.mean(dim=0)\n",
    "\n",
    "    std_x = torch.sqrt(x.var(dim=0) + 0.0001)\n",
    "    std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
    "    std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
    "\n",
    "    cov_x = (x.T @ x) / (tr_batch_size - 1)\n",
    "    cov_y = (y.T @ y) / (tr_batch_size - 1)\n",
    "    cov_loss = off_diagonal(cov_x).pow_(2).sum().div(\n",
    "        x.shape[1]\n",
    "    ) + off_diagonal(cov_y).pow_(2).sum().div(x.shape[1])\n",
    "    \n",
    "    # self.num_features -> rep_dim?\n",
    "    loss = (\n",
    "        sim_coeff * repr_loss\n",
    "        + std_coeff * std_loss\n",
    "        + cov_coeff * cov_loss\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def atoms_dictionary(atomic_num):\n",
    "    #print(\"atomic_num: \", atomic_num)\n",
    "    atomic_symbol = periodic_table.GetElementSymbol(atomic_num)\n",
    "    return atomic_symbol\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d49f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XenonPy_transform(df, df_dict_column):\n",
    "    cal = Compositions()\n",
    "    comps = df[df_dict_column]\n",
    "    descriptors = cal.transform(comps)\n",
    "    column_names = list(descriptors.columns)\n",
    "    scaler = preprocessing.StandardScaler().fit(descriptors)\n",
    "    descriptors = scaler.transform(descriptors)\n",
    "    descriptors = pd.DataFrame(descriptors, columns = column_names)\n",
    "    descriptors.rename(lambda x: str(x), axis='columns')\n",
    "    descriptors.columns = descriptors.columns.astype(str)\n",
    "    return(descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad42ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mol_dict(batch):\n",
    "    \n",
    "    graph_chem_formulae_dictionaries = pd.DataFrame()\n",
    "    if not graph_chem_formulae_dictionaries.empty:\n",
    "        graph_chem_formulae_dictionaries.drop(columns = 'formula')\n",
    "\n",
    "    node_to_graph_indicator = pd.DataFrame(batch.batch).astype(\"int\")\n",
    "    node = pd.DataFrame(batch.x).astype(\"int\")\n",
    "    mol_list = []\n",
    "    j = 0\n",
    "    mol_dict = {}\n",
    "    for i in range(len(batch.z)):\n",
    "            #get a dictionary for each graph that contains chemical formula\n",
    "                #format for use for XenonPy\n",
    "        if j == int(node_to_graph_indicator.iloc[i]):\n",
    "                #add this ith atom to to the dictionary for the jth graph\n",
    "                #atoms_dictionary(atomic_num)\n",
    "                #call function to add element to molecular dictionary\n",
    "            element = atoms_dictionary(int(node[5].iloc[i]))\n",
    "            if element in mol_dict:\n",
    "                mol_dict[element] = mol_dict[element] + 1\n",
    "            else:\n",
    "                mol_dict[element] = 1\n",
    "        else: #need to move to next graph\n",
    "                #Insert these dictionaries to each row in the df\n",
    "            mol_list.append(mol_dict)\n",
    "            mol_dict = {}\n",
    "            element = atoms_dictionary(int(node[5].iloc[i]))\n",
    "            j += 1\n",
    "\n",
    "    mol_list.append(mol_dict) #need to append the last dict\n",
    "    graph_chem_formulae_dictionaries.insert(0, 'formula', mol_list)\n",
    "    for i in range(len(batch.y) - 1):\n",
    "        if mol_list[i]:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Empty!!\", \" location: \", i)\n",
    "\n",
    "    return graph_chem_formulae_dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f1c487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5307687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rep_dim = 128\n",
    "        self.emb_dim = 256\n",
    "        \n",
    "        # Data under graph\n",
    "        self.conv1 = GCNConv(whole_dataset.num_node_features, self.rep_dim // 2)\n",
    "        self.bn1 = nn.BatchNorm1d(self.rep_dim // 2)\n",
    "        self.a1 = nn.LeakyReLU(0.02)\n",
    "        \n",
    "        self.conv2 = GCNConv(self.rep_dim // 2, self.rep_dim) # To Rep Space\n",
    "        self.bn2 = nn.BatchNorm1d(self.rep_dim)\n",
    "        \n",
    "        # Projection to representation\n",
    "        self.mpool1 = gnn.global_mean_pool\n",
    "        #self.fc1 = nn.Linear(self.rep_dim, self.rep_dim)\n",
    "        \n",
    "        # Graph 2\n",
    "        self.conv3 = GCNConv(self.rep_dim, self.rep_dim * 2) # To Emb Space\n",
    "        self.bn3 = nn.BatchNorm1d(self.rep_dim * 2)\n",
    "        \n",
    "        # Projection to embedding\n",
    "        self.mpool2 = gnn.global_mean_pool\n",
    "        self.fc2 = nn.Linear(self.emb_dim, self.emb_dim) # Linear to rep?\n",
    "            #might want to get rid of this\n",
    "        \n",
    "    def forward(self, data, binds):\n",
    "        x = data[0].float().to(device)\n",
    "        edge_index = data[1].to(device)\n",
    "        \n",
    "        # Input graph to GConv\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.a1(self.bn1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.bn2(self.conv2(x, edge_index))\n",
    "        \n",
    "        # GConv outputs projected to representation space\n",
    "        #print('before pool: ', x.shape)\n",
    "        x_rep = self.mpool1(x, binds)\n",
    "        #print('pooled: ', x_rep.shape)\n",
    "        \n",
    "        #x_rep = self.fc1(x_rep)\n",
    "        #print('projected: ', x_rep.shape, 'gconv', x.shape)\n",
    "        \n",
    "        x_emb = self.bn3(self.conv3(x, edge_index))\n",
    "        #print('x emb after conv3', x_emb.shape)\n",
    "        x_emb = self.mpool2(x_emb, binds)\n",
    "        #print('after pool', x_emb.shape)\n",
    "        x_emb = self.fc2(x_emb)\n",
    "        #print('after fc2', x_emb.shape)\n",
    "        \n",
    "        return x_rep, x_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "90bb4b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "model = GCN().to(device)\n",
    "\n",
    "#vicreg loss function parameters\n",
    "sim_coeff = 25\n",
    "std_coeff = 25\n",
    "cov_coeff = 1\n",
    "\n",
    "#list of training augmentations\n",
    "tr_augmentations = [#A.RWSampling(num_seeds=1000, walk_length=10),\n",
    "                      A.NodeDropping(pn=0.1),\n",
    "                      A.FeatureMasking(pf=0.1),\n",
    "                      A_alternate.EdgeRemoving(pe=0.1)]\n",
    "\n",
    "#list of validation augmentations\n",
    "val_augmentations = []\n",
    "\n",
    "#list of test augmentations\n",
    "test_augmentations = []\n",
    "\n",
    "#number of choices for augmentations for training, validation, and test sets, respectively\n",
    "tr_num_choices = 1\n",
    "val_num_choices = 0\n",
    "test_num_choices = 0\n",
    "\n",
    "#Adam parameters\n",
    "Adam_learning_rate = 0.002\n",
    "Adam_weight_decay = 5e-4\n",
    "adam = {'lr': Adam_learning_rate, \n",
    "        'weight_decay': Adam_weight_decay\n",
    "       }\n",
    "\n",
    "#dictionary of optimizers used\n",
    "optimizers = {}\n",
    "optimizers['adam'] = adam\n",
    "\n",
    "\n",
    "\n",
    "#dictionary of loss functions used\n",
    "loss_functions_used = {}\n",
    "\n",
    "vicreg = {'sim_coeff': sim_coeff,\n",
    "          'std_coeff': std_coeff,\n",
    "          'cov_coeff': cov_coeff\n",
    "         }\n",
    "\n",
    "loss_functions_used['vicreg'] = vicreg\n",
    "\n",
    "augmentations_used = {}\n",
    "augmentations_used['tr_augmentations'] = tr_augmentations\n",
    "augmentations_used['val_augmentations'] = val_augmentations\n",
    "augmentations_used['test_augmentations'] = test_augmentations\n",
    "augmentations_used['tr_num_choices'] = tr_num_choices\n",
    "augmentations_used['val_num_choices'] = val_num_choices\n",
    "augmentations_used['test_num_choices'] = test_num_choices\n",
    "\n",
    "\n",
    "#dictionary of parameters used for downstream Linear Models\n",
    "lm_parameters = {'default': 'used default for all parameters'}\n",
    "\n",
    "#dictionary of parameters used for downstream Random Forest models\n",
    "rf_parameters = {'n_estimators': 10, \n",
    "                 'max_depth': 10 }\n",
    "\n",
    "#dictionary of parameters used for downstream LightGBM models\n",
    "lgbm_parameters = {'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': {'l2', 'l1'},\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'force_col_wise': 'true',\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': -1,\n",
    "            'num_boost_round': 20,\n",
    "            'callbacks': '[lgb.early_stopping(stopping_rounds=5)]'\n",
    "                  }\n",
    "\n",
    "downstream_model_parameters = {}\n",
    "downstream_model_parameters['lm_parameters'] = lm_parameters\n",
    "downstream_model_parameters['rf_parameters'] = rf_parameters\n",
    "downstream_model_parameters['lgbm_parameters'] = lgbm_parameters\n",
    "\n",
    "\n",
    "\n",
    "parameters_used['loss_functions_used'] = loss_functions_used\n",
    "parameters_used['augmentations_used'] = augmentations_used\n",
    "parameters_used['optimizer'] = optimizer\n",
    "parameters_used['adam_learning_rate'] = Adam_learning_rate\n",
    "parameters_used['adam_weight_decay'] = Adam_weight_decay\n",
    "parameters_used['downstream_model_parameters'] = downstream_model_parameters\n",
    "\n",
    "tr_aug = A.RandomChoice(tr_augmentations, #edge_adj was deprecated, so need to use edge_ something instead\n",
    "                      num_choices=tr_num_choices)\n",
    "#should do many other types of augmentations\n",
    "    #train models on all but one augmentations and see which work best\n",
    "        #ablation study!\n",
    "val_aug = A.RandomChoice(val_augmentations, num_choices = val_num_choices)\n",
    "test_aug = A.RandomChoice(test_augmentations, num_choices = test_num_choices)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=Adam_learning_rate, weight_decay=Adam_weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2a4fcd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(parameters_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a76078cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(loss_per_epoch, val_loss):\n",
    "    train_values = loss_per_epoch\n",
    "    val_values = val_loss\n",
    " \n",
    "    # Generate a sequence of integers to represent the epoch numbers\n",
    "    epochs = range(0, len(loss_per_epoch))\n",
    " \n",
    "    # Plot and label the training and validation loss values\n",
    "    plt.plot(epochs, train_values, label='Training Loss')\n",
    "    plt.plot(epochs, val_values, label='Validation Loss')\n",
    " \n",
    "    # Add in a title and axes labels\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    " \n",
    "    # Set the tick locations\n",
    "\n",
    "    plt.xticks(arange(0, len(loss_per_epoch), max(math.floor(len(loss_per_epoch)/10), 1)))\n",
    " \n",
    "    # Display the plot\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a3d7dff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training!\n",
      "epoch 0 train loss: 19.795638537002823\n",
      "epoch 0 val loss: 15.89559217979168\n",
      "epoch 1 train loss: 25.43859478578729\n",
      "epoch 1 val loss: 17.790815139638966\n",
      "Done augmenting!\n"
     ]
    }
   ],
   "source": [
    "tr_graph_chem_formulae_dictionaries = pd.DataFrame()\n",
    "n_epochs = 1\n",
    "epoch_loss = []\n",
    "val_epoch_loss = []\n",
    "print(\"Start training!\")\n",
    "for epoch in range(0,n_epochs+1):\n",
    "    #print(\"epoch: \", epoch)\n",
    "    epoch_losses = []\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_inds = batch.batch.to(device)\n",
    "      \n",
    "        # batch of graphs has edge attribs, node attribs - (n_nodes, n_features+1) -> concat (n_nodes, attrib1)\n",
    "\n",
    "        batch.x = batch.x.float()#.to(device)\n",
    "        #batch.edge_index = batch.edge_index.to(device)\n",
    "\n",
    "        # Barlow - get 2 random views of batch\n",
    "        b1 = tr_aug(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        b2 = tr_aug(batch.x, batch.edge_index, batch.edge_attr)\n",
    "\n",
    "        # Embed each batch (ignoring representations)\n",
    "        r1, e1 = model(b1, batch_inds)\n",
    "        r2, e2 = model(b2, batch_inds)\n",
    "\n",
    "        loss = VicRegLoss(e1, e2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses.append(loss.data.item())\n",
    "        \n",
    "    epoch_loss.append(sum(epoch_losses) / len(epoch_losses))\n",
    "    print('epoch', epoch,'train loss:', sum(epoch_losses) / len(epoch_losses))\n",
    "\n",
    "    \n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    \n",
    "    # VicReg Validation Loss\n",
    "    val_epoch_losses = []\n",
    "    for batch in val_loader:\n",
    "        with torch.no_grad():\n",
    "            # VicReg validation loss\n",
    "            b1 = val_aug(batch.x, batch.edge_index, batch.edge_attr)\n",
    "            b2 = val_aug(batch.x, batch.edge_index, batch.edge_attr)\n",
    "            r1, e1 = model(b1, batch.batch.to(device))\n",
    "            r2, e2 = model(b2, batch.batch.to(device))\n",
    "                \n",
    "            val_loss = VicRegLoss(e1, e2)\n",
    "            val_epoch_losses.append(val_loss.data.item())\n",
    "            \n",
    "\n",
    "    val_epoch_loss.append(sum(val_epoch_losses) / len(val_epoch_losses))    \n",
    "    print('epoch', epoch,'val loss:', sum(val_epoch_losses) / len(val_epoch_losses))\n",
    "\n",
    "    \n",
    "print(\"Done augmenting!\")        \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a409dd59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cd900cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot train-val loss curves\n",
    "plot_loss_curves(epoch_loss, val_epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef83d662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b32018a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to embed data\n",
    "def get_embeddings(data_loader, model, aug):\n",
    "    x = pd.DataFrame()\n",
    "    x_no_aug = pd.DataFrame()\n",
    "    y = pd.DataFrame()\n",
    "    y_no_aug = pd.DataFrame()\n",
    "    graph_chem_formulae_dictionaries = pd.DataFrame()\n",
    "    for batch in data_loader: # take entire train set\n",
    "        x_tabular_no_aug = pd.DataFrame(batch.x).astype(\"float\")\n",
    "        x_no_aug = pd.concat([x_no_aug, x_tabular_no_aug], ignore_index = True)\n",
    "        y_tabular_no_aug = pd.DataFrame(batch.y).astype(\"float\")\n",
    "        y_no_aug = pd.concat([y_no_aug, y_tabular_no_aug], ignore_index = True)\n",
    "        graph_chem_formulae_dictionaries = pd.concat([graph_chem_formulae_dictionaries, get_mol_dict(batch)], ignore_index = True)\n",
    "        with torch.no_grad():\n",
    "            # Embed training set under model\n",
    "            rep, _ = model(aug(batch.x, batch.edge_index, batch.edge_attr), batch.batch.to(device))\n",
    "            if torch.cuda.is_available():\n",
    "                rep = rep.to(\"cpu\")\n",
    "            rep_tabular = pd.DataFrame(rep.numpy())\n",
    "            x = pd.concat([x, rep_tabular], ignore_index = True)\n",
    "            y_tabular = pd.DataFrame(batch.y).astype(\"float\")\n",
    "            y = pd.concat([y, y_tabular], ignore_index = True)\n",
    "    \n",
    "    return x, y, graph_chem_formulae_dictionaries, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ec2250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a7d94ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get embeddings for training set\n",
    "x_tr, y_tr, tr_graph_chem_formulae_dictionaries, model = get_embeddings(train_loader, model, tr_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e5b818d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get embeddings for validation set\n",
    "x_val, y_val, val_graph_chem_formulae_dictionaries, model = get_embeddings(val_loader, model, val_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "949b5048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get embeddings for test set\n",
    "x_test, y_test, test_graph_chem_formulae_dictionaries, model = get_embeddings(test_loader, model, test_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99766bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29468f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I set a random seed, so I can do this step in a separate piece of code\n",
    "    #Then, save file to folder\n",
    "    #This way, do not have to do XenonPy transformation for every experiment iteration\n",
    "\n",
    "#Get XenonPy transformation for training set\n",
    "print(\"XenonPy transformation for training set:\")\n",
    "tr_df_XenonPy = XenonPy_transform(tr_graph_chem_formulae_dictionaries, 'formula')\n",
    "print(\"Done with XenonPy transformation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32df2b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get XenonPy transformation for validation set\n",
    "print(\"XenonPy transformation for val set:\")\n",
    "val_df_XenonPy = XenonPy_transform(val_graph_chem_formulae_dictionaries, 'formula')\n",
    "print(\"Done with XenonPy transformation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a88c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get XenonPy transformation for test set\n",
    "#print(\"XenonPy transformation for test set:\")\n",
    "#val_df_XenonPy = XenonPy_transform(test_graph_chem_formulae_dictionaries, 'formula')\n",
    "#print(\"Done with XenonPy transformation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6808e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_models(x_train, x_test, y_train, y_test, lm_parameters):\n",
    "    the = -2\n",
    "    return the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_models(x_train, x_test, y_train, y_test, rf_parameters):\n",
    "    the = -2\n",
    "    return the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4706afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_models(x_train, x_test, y_train, y_test, lgbm_parameters):\n",
    "    the = -2\n",
    "    return the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21297cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf49008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4abc8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3177b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function to run linear models\n",
    "def linear_models(x_train, x_test, y_train, y_test, list_target_features):\n",
    "    # For each task in QM9\n",
    "    results_list = [] #list of dictionaries, where each dictionary contains the results from that model for each feature\n",
    "    lgb_results_dict = {}\n",
    "    rf_results_dict = {}\n",
    "    lm_results_dict = {}\n",
    "    model_info = {}\n",
    "    means_vector = y_train.mean(axis = 0)\n",
    "    rep_means_vectors = means_vector.repeat(x_train.shape[0]) #create a vector where each entry is the mean\n",
    "    for target_feature in range(y_test.shape[1]):\n",
    "\n",
    "        # Fit a model on model representation of train set:\n",
    "        #Need to drop missing values for linear models, since they do not allow these\n",
    "        lm = LinearRegression().fit(x_train.values, y_train[target_feature].values)\n",
    "        lm_yhat = lm.predict(x_test.values)\n",
    "        lm_score = mean_squared_error(y_test[target_feature].values, lm_yhat)\n",
    "        print(\"Linear Regression Model MSE for \", list_target_features[target_feature], \": \", lm_score)\n",
    "        lm_results_dict[\"LM_\" + qm9_index_list[target_feature]] = lm_score\n",
    "        r2 = r2_score(y_test[target_feature].values, lm_yhat)\n",
    "        print(\"R^2 score for linear model: \", r2)\n",
    "        \n",
    "        \n",
    "        #Fit Random Forest models here:\n",
    "        #rf = RandomForestRegressor(n_estimators=10, max_depth=10 )\n",
    "        #rf.fit(x_train, y_train[target_feature])\n",
    "        #rf_yhat = rf.predict(x_test)\n",
    "        #rf_score = mean_squared_error(y_test[target_feature], rf_yhat)\n",
    "        #print(\"RF Model Mean-Squared-Error for \", list_target_features[target_feature], \": \", rf_score)\n",
    "        #rf_results_dict[\"RF_\" + qm9_index_list[target_feature]] = rf_score\n",
    "        \n",
    "        \n",
    "        #Fit LightGBM models here (LightGBM is supposedly better than XGBoost):\n",
    "        lgb_train = lgb.Dataset(x_train.values, y_train[target_feature].values, params={'verbose': -1})\n",
    "        lgb_eval = lgb.Dataset(x_test.values, y_test[target_feature].values, reference=lgb_train, params={'verbose': -1})\n",
    "        params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': {'l2', 'l1'},\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'force_col_wise': 'true',\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': -1\n",
    "        }\n",
    "        \n",
    "        gbm = lgb.train(params,\n",
    "                        lgb_train,\n",
    "                        num_boost_round=20,\n",
    "                        valid_sets=lgb_eval,\n",
    "                        callbacks=[lgb.early_stopping(stopping_rounds=5)])\n",
    "        lgb_yhat = gbm.predict(x_test.values, num_iteration=gbm.best_iteration)\n",
    "        lgb_score = mean_squared_error(y_test[target_feature].values, lgb_yhat)\n",
    "        print(\"LightGBM Model MSE for \", list_target_features[target_feature], \": \", lgb_score)\n",
    "        lgb_results_dict[\"Light_GBM_\" + qm9_index_list[target_feature]] = lgb_score\n",
    "        \n",
    "        # Test the model on model representation of val set\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        rep_means_vectors = means_vector[target_feature].repeat(x_test.shape[0])\n",
    "        baseline = mean_squared_error(y_test[target_feature].values, rep_means_vectors)\n",
    "        #baseline is a model that always outputs the mean of the training sample\n",
    "        print(\"Baseline MSE for \", list_target_features[target_feature], \": \", baseline)\n",
    "        \n",
    "        \n",
    "    results_list.append(lm_results_dict) #append Linear Model results dictionary to results list    \n",
    "    results_list.append(lgb_results_dict) #append Light GBM results dictionary to results list\n",
    "    #results_list.append(rf_results_dict) #append Random Forest results dictionary to results list\n",
    "    \n",
    "    \n",
    "    return results_list, model_info\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde40c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to make sure that I am getting the correct graphs for y's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ccf5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join XenonPy transformations with x_tr and x_val\n",
    "x_tr.join(tr_df_XenonPy)\n",
    "x_val.join(val_df_XenonPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27a7a44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a33d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7584a616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c6f2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53766709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f91d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_tr = x_tr.drop(index=[83501, 56941])\n",
    "#need to drop the two rows with extremely large Rotational Constant A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca58fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0b4097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_tr = y_tr.drop(index=[83501, 56941])\n",
    "#need to drop the two rows with extremely large Rotational Constant A\n",
    "#need to also drop extreme values for y_val, y_test, x_tr, x_val, and x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6fd975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_extreme_values(df):\n",
    "    \n",
    "    for column in range(df.shape[1]):\n",
    "        sorted_index_array = np.argsort(df[column])\n",
    "        sorted_array = df[column][sorted_index_array]\n",
    "        n = 10\n",
    "\n",
    "        # find n largest value\n",
    "        max_rslt = sorted_array[-n : ]\n",
    "        min_rslt = sorted_array[ : n]\n",
    "        #print(rslt)\n",
    "        # show the output\n",
    "        print(qm9_index_list[column], \"max values:\\n\", max_rslt)\n",
    "        print(qm9_index_list[column], \"min values:\\n\", min_rslt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050e7774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_extreme_values(y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd01862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_extreme_values(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868cf25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_extreme_values(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a5fda2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_extreme_values(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d55d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_extreme_values(x_val) #need to do this before transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc668d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_extreme_values(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a22495f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb5ca2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d75e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_tr = pd.concat([x_tr, x_val]) #tr and val combined for training set\n",
    "#y_tr = pd.concat([y_tr, y_val]) #tr and val combined for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bbbf5b47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model MSE for  Dipole moment :  1.3473452498486902\n",
      "R^2 score for linear model:  0.30536101773978064\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 1.31685\tvalid_0's l1: 0.927227\n",
      "LightGBM Model MSE for  Dipole moment :  1.316851972498849\n",
      "Baseline MSE for  Dipole moment :  1.9529090393714126\n",
      "Linear Regression Model MSE for  Isotropic polarizability :  132.2354955500371\n",
      "R^2 score for linear model:  -0.665553823427715\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 139.004\tvalid_0's l1: 9.72756\n",
      "LightGBM Model MSE for  Isotropic polarizability :  139.0037233620146\n",
      "Baseline MSE for  Isotropic polarizability :  173.16770199737104\n",
      "Linear Regression Model MSE for  Highest occupied molecular orbital energy :  0.25188408181235417\n",
      "R^2 score for linear model:  0.41365889772580755\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.331859\tvalid_0's l1: 0.42893\n",
      "LightGBM Model MSE for  Highest occupied molecular orbital energy :  0.3318594744835516\n",
      "Baseline MSE for  Highest occupied molecular orbital energy :  0.449256003913676\n",
      "Linear Regression Model MSE for  Lowest unoccupied molecular orbital energy :  0.7480327116577857\n",
      "R^2 score for linear model:  0.5793914627295427\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.919118\tvalid_0's l1: 0.794352\n",
      "LightGBM Model MSE for  Lowest unoccupied molecular orbital energy :  0.9191177784255699\n",
      "Baseline MSE for  Lowest unoccupied molecular orbital energy :  1.781967934655151\n",
      "Linear Regression Model MSE for  Gap between previous 2 :  0.9299077949716932\n",
      "R^2 score for linear model:  0.48386204398727284\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 1.05327\tvalid_0's l1: 0.868272\n",
      "LightGBM Model MSE for  Gap between previous 2 :  1.053266084988824\n",
      "Baseline MSE for  Gap between previous 2 :  1.8414746633575791\n",
      "Linear Regression Model MSE for  Electronic spatial extent :  121475.2918859026\n",
      "R^2 score for linear model:  -0.9799421626243743\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's l2: 108471\tvalid_0's l1: 278.299\n",
      "LightGBM Model MSE for  Electronic spatial extent :  108471.2229861819\n",
      "Baseline MSE for  Electronic spatial extent :  109582.64370449651\n",
      "Linear Regression Model MSE for  Zero point vibrational energy :  0.4535891119779995\n",
      "R^2 score for linear model:  0.48291417459577035\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.466363\tvalid_0's l1: 0.554807\n",
      "LightGBM Model MSE for  Zero point vibrational energy :  0.46636264573567343\n",
      "Baseline MSE for  Zero point vibrational energy :  1.0606056324048596\n",
      "Linear Regression Model MSE for  Internal energy at 0K :  3070912.040389841\n",
      "R^2 score for linear model:  -1.1030768856187927\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 2.71848e+06\tvalid_0's l1: 1378.75\n",
      "LightGBM Model MSE for  Internal energy at 0K :  2718476.4395744307\n",
      "Baseline MSE for  Internal energy at 0K :  3296046.8127753674\n",
      "Linear Regression Model MSE for  Internal energy at 298.15K :  3067148.898200079\n",
      "R^2 score for linear model:  -1.1005407168329193\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 2.71839e+06\tvalid_0's l1: 1378.74\n",
      "LightGBM Model MSE for  Internal energy at 298.15K :  2718394.9822032223\n",
      "Baseline MSE for  Internal energy at 298.15K :  3295975.1441105837\n",
      "Linear Regression Model MSE for  Enthalpy at 298.15K :  3068443.1628520763\n",
      "R^2 score for linear model:  -1.1014271558916566\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 2.71839e+06\tvalid_0's l1: 1378.74\n",
      "LightGBM Model MSE for  Enthalpy at 298.15K :  2718394.938184949\n",
      "Baseline MSE for  Enthalpy at 298.15K :  3295975.0843308805\n",
      "Linear Regression Model MSE for  Free energy at 298.15K :  3068583.0091793295\n",
      "R^2 score for linear model:  -1.1013991636671916\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 2.71861e+06\tvalid_0's l1: 1378.78\n",
      "LightGBM Model MSE for  Free energy at 298.15K :  2718605.169966919\n",
      "Baseline MSE for  Free energy at 298.15K :  3296172.3501171824\n",
      "Linear Regression Model MSE for  Heat capacity at 298.15K :  28.492401891014904\n",
      "R^2 score for linear model:  -0.40434443839961687\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 24.9783\tvalid_0's l1: 3.92496\n",
      "LightGBM Model MSE for  Heat capacity at 298.15K :  24.97829189629471\n",
      "Baseline MSE for  Heat capacity at 298.15K :  30.048005554202305\n",
      "Linear Regression Model MSE for  Atomization energy at 0K :  136.79566107496404\n",
      "R^2 score for linear model:  -0.12931996756912967\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 139.25\tvalid_0's l1: 9.70263\n",
      "LightGBM Model MSE for  Atomization energy at 0K :  139.2498353034429\n",
      "Baseline MSE for  Atomization energy at 0K :  201.28208918863683\n",
      "Linear Regression Model MSE for  Atomization energy at 298.15K :  138.63816219329985\n",
      "R^2 score for linear model:  -0.12549029761417674\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 141.449\tvalid_0's l1: 9.78311\n",
      "LightGBM Model MSE for  Atomization energy at 298.15K :  141.44938797338813\n",
      "Baseline MSE for  Atomization energy at 298.15K :  204.38462888543398\n",
      "Linear Regression Model MSE for  Atomization enthalpy at 298.15K :  140.23734801400616\n",
      "R^2 score for linear model:  -0.12245165098547561\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 142.658\tvalid_0's l1: 9.82438\n",
      "LightGBM Model MSE for  Atomization enthalpy at 298.15K :  142.65829154904335\n",
      "Baseline MSE for  Atomization enthalpy at 298.15K :  207.04127148098866\n",
      "Linear Regression Model MSE for  Atomization free energy at 298.15K :  116.46520148010153\n",
      "R^2 score for linear model:  -0.13772817187184638\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 118.979\tvalid_0's l1: 8.98543\n",
      "LightGBM Model MSE for  Atomization free energy at 298.15K :  118.9785314117667\n",
      "Baseline MSE for  Atomization free energy at 298.15K :  171.1032640099154\n",
      "Linear Regression Model MSE for  Rotational constant A :  14208.152549811914\n",
      "R^2 score for linear model:  -577.4344908094185\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l2: 2396.79\tvalid_0's l1: 5.50464\n",
      "LightGBM Model MSE for  Rotational constant A :  2396.793384028109\n",
      "Baseline MSE for  Rotational constant A :  56.565589864015024\n",
      "Linear Regression Model MSE for  Rotational constant B :  19.760342719020976\n",
      "R^2 score for linear model:  -0.02908137302228453\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[17]\tvalid_0's l2: 17.1699\tvalid_0's l1: 0.665196\n",
      "LightGBM Model MSE for  Rotational constant B :  17.169910004255655\n",
      "Baseline MSE for  Rotational constant B :  19.434006185677646\n",
      "Linear Regression Model MSE for  Rotational constant C :  19.24000002701949\n",
      "R^2 score for linear model:  -0.016390085498361406\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 16.9233\tvalid_0's l1: 0.50332\n",
      "LightGBM Model MSE for  Rotational constant C :  16.92325305145209\n",
      "Baseline MSE for  Rotational constant C :  19.08936755254312\n"
     ]
    }
   ],
   "source": [
    "results_list, model_info = linear_models(x_tr, x_test, y_tr, y_test, qm9_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4911fc9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d95f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_models(x_tr_no_aug, x_val_no_aug, y_tr_no_aug, y_val_no_aug, qm9_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e98619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a03b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4a9fdd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record end time\n",
    "t_1 = timeit.default_timer()\n",
    " \n",
    "# calculate elapsed time and print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc76a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "455219dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'LM_Dipole_moment': 1.3473452498486902, 'LM_Isotropic_polarizability': 132.2354955500371, 'LM_Highest_occupied_molecular_orbital_energy': 0.25188408181235417, 'LM_Lowest_unoccupied_molecular_orbital_energy': 0.7480327116577857, 'LM_Gap_between_previous_2': 0.9299077949716932, 'LM_Electronic_spatial_extent': 121475.2918859026, 'LM_Zero_point_vibrational_energy': 0.4535891119779995, 'LM_Internal_energy_at_0K': 3070912.040389841, 'LM_Internal_energy_at_298.15K': 3067148.898200079, 'LM_Enthalpy_at_298.15K': 3068443.1628520763, 'LM_Free_energy_at_298.15K': 3068583.0091793295, 'LM_Heat_capacity_at_298.15K': 28.492401891014904, 'LM_Atomization_energy_at_0K': 136.79566107496404, 'LM_Atomization_energy_at_298.15K': 138.63816219329985, 'LM_Atomization_enthalpy_at_298.15K': 140.23734801400616, 'LM_Atomization_free_energy_at_298.15K': 116.46520148010153, 'LM_Rotational_constant_A': 14208.152549811914, 'LM_Rotational_constant_B': 19.760342719020976, 'LM_Rotational_constant_C': 19.24000002701949}, {'Light_GBM_Dipole_moment': 1.316851972498849, 'Light_GBM_Isotropic_polarizability': 139.0037233620146, 'Light_GBM_Highest_occupied_molecular_orbital_energy': 0.3318594744835516, 'Light_GBM_Lowest_unoccupied_molecular_orbital_energy': 0.9191177784255699, 'Light_GBM_Gap_between_previous_2': 1.053266084988824, 'Light_GBM_Electronic_spatial_extent': 108471.2229861819, 'Light_GBM_Zero_point_vibrational_energy': 0.46636264573567343, 'Light_GBM_Internal_energy_at_0K': 2718476.4395744307, 'Light_GBM_Internal_energy_at_298.15K': 2718394.9822032223, 'Light_GBM_Enthalpy_at_298.15K': 2718394.938184949, 'Light_GBM_Free_energy_at_298.15K': 2718605.169966919, 'Light_GBM_Heat_capacity_at_298.15K': 24.97829189629471, 'Light_GBM_Atomization_energy_at_0K': 139.2498353034429, 'Light_GBM_Atomization_energy_at_298.15K': 141.44938797338813, 'Light_GBM_Atomization_enthalpy_at_298.15K': 142.65829154904335, 'Light_GBM_Atomization_free_energy_at_298.15K': 118.9785314117667, 'Light_GBM_Rotational_constant_A': 2396.793384028109, 'Light_GBM_Rotational_constant_B': 17.169910004255655, 'Light_GBM_Rotational_constant_C': 16.92325305145209}]\n"
     ]
    }
   ],
   "source": [
    "print(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebe4112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5386ce4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "96262e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 2525.5 seconds\n",
      "Elapsed time: 42.09 minutes\n",
      "Elapsed time: 0.7 hours\n"
     ]
    }
   ],
   "source": [
    "elapsed_time = round((t_1 - t_0) , 1)\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "elapsed_time_minutes = round((elapsed_time/60), 2)\n",
    "print(f\"Elapsed time: {elapsed_time_minutes} minutes\")\n",
    "elapsed_time_hours = round((elapsed_time/3600), 2)\n",
    "print(f\"Elapsed time: {elapsed_time_hours} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d020e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_info = {'dataset':dataset, 'hours':elapsed_time_hours, 'minutes':elapsed_time_minutes, 'seconds':elapsed_time}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb70c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False\n",
    "if run == True:\n",
    "    print(\"Saved!\")\n",
    "    #save experimental results\n",
    "    current_time = datetime.now()\n",
    "    dt_string = current_time.strftime(\"%Y-%m-%d_%H_%M\")\n",
    "    directory = dt_string\n",
    "    parent_dir = '/home/ewvertina/Molecular_modelling/Experiment_Results/'\n",
    "    path = os.path.join(parent_dir, directory)\n",
    "    os.mkdir(path)\n",
    "    path_state_dict = path + '/state_dict'\n",
    "    path_results_dict = path + '/results_dict.txt'\n",
    "    path_runtime = path + '/runtime.txt'\n",
    "    path_parameters = path + '/parameters_used.txt'\n",
    "    path_fig = path + '/train_test_loss.png'\n",
    "    \n",
    "    #save NN model as a torch dictionary\n",
    "    torch.save(model.state_dict(), path_state_dict)\n",
    "    torch.save(results_dict, path_results_dict)\n",
    "    torch.save(other_info, path_runtime) #save which dataset, runtime\n",
    "    torch.save(parameters_used, path_parameters) #saves all parameters used\n",
    "    plt.savefig(path_fig) #save train-val loss figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f0640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "48c6280b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66527be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65cb39f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304940bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23057d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeae51b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4811a425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2717af52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe50c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4885e41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebdb5db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c40dce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bb4d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edfaa43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b67d5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f9fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfc35b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a46903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
