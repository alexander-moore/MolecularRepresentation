{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e6fa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code is running!\n"
     ]
    }
   ],
   "source": [
    "# https://arxiv.org/abs/1610.02415\n",
    "\n",
    "# https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html\n",
    "print(\"Code is running!\")\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.nn as gnn\n",
    "\n",
    "from torch_geometric.datasets import QM9\n",
    "import GCL.augmentors\n",
    "import GCL.augmentors as A\n",
    "import edge_removing as A_alternate\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import RidgeClassifierCV, LogisticRegression, LinearRegression\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "from rdkit.Chem import PeriodicTable\n",
    "from rdkit import Chem\n",
    "from xenonpy.datatools import preset\n",
    "from xenonpy.descriptor import Compositions\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from matplotlib.pylab import plt\n",
    "from numpy import arange\n",
    "import math\n",
    "import timeit\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import ipynb.fs.full.XenonPy_transformation as XPy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e72ca970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following are needed to use PyTorch Lightning\n",
    "from functools import partial\n",
    "from typing import Sequence, Tuple, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as VisionF\n",
    "from pytorch_lightning import Callback, LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.functional import accuracy\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.models.resnet import resnet18\n",
    "from torchvision.utils import make_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be3d6a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#record start time\n",
    "t_0 = timeit.default_timer()\n",
    "# call function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "984ef87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QM9 dataset list of input features and list of target features\n",
    "dataset = \"QM9\"\n",
    "\n",
    "#list of input features in QM9 dataset\n",
    "x_index = {0: 'H atom?',\n",
    "1: 'C atom?',\n",
    "2: 'N atom?',\n",
    "3: 'O atom?',\n",
    "4: 'F atom?',\n",
    "5: 'atomic_number',\n",
    "6: 'aromatic',\n",
    "7: 'sp1',\n",
    "8: 'sp2',\n",
    "9: 'sp3',\n",
    "10: 'num_hs'}\n",
    "x_index_list = ['H atom?', \n",
    "                'C atom?', \n",
    "                'N atom?', \n",
    "                'O atom?', \n",
    "                'F atom?', \n",
    "                'atomic_number', 'aromatic', \n",
    "                'sp1',\n",
    "                'sp2',\n",
    "                'sp3',\n",
    "                'num_hs']\n",
    "\n",
    "\n",
    "#list of target features in QM9 dataset\n",
    "qm9_index = {0: 'Dipole_moment',\n",
    "1: 'Isotropic_polarizability',\n",
    "2: 'HOMO',\n",
    "3: 'LUMO',\n",
    "4: 'HOMO_LUMO_gap',\n",
    "5: 'Electronic_spatial_extent',\n",
    "6: 'Zero_point_vibrational_energy',\n",
    "7: 'Internal_energy_at_0K',\n",
    "8: 'Internal_energy_at_298.15K',\n",
    "9: 'Enthalpy_at_298.15K',\n",
    "10: 'Free_energy_at_298.15K',\n",
    "11: 'Heat_capacity_at_298.15K',\n",
    "12: 'Atomization_energy_at_0K',\n",
    "13: 'Atomization_energy_at_298.15K',\n",
    "14: 'Atomization_enthalpy_at_298.15K',\n",
    "15: 'Atomization_free_energy_at_298.15K',\n",
    "16: 'Rotational_constant_A',\n",
    "17: 'Rotational_constant_B',\n",
    "18: 'Rotational_constant_C'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b39d0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for GCL methods\n",
    "\n",
    "tr_batch_size = 1000\n",
    "val_batch_size = 200\n",
    "test_batch_size = 100\n",
    "tr_ratio = 0.9\n",
    "val_ratio = 0.09\n",
    "test_ratio = 0.01\n",
    "num_workers = 2\n",
    "shuffle = True\n",
    "qm9_index_list = ['Dipole_moment', \n",
    "                  'Isotropic_polarizability',\n",
    "                  'Highest_occupied_molecular_orbital_energy',\n",
    "                  'Lowest_unoccupied_molecular_orbital_energy',\n",
    "                  'Gap_between_previous_2',\n",
    "                  'Electronic_spatial_extent',\n",
    "                  'Zero_point_vibrational_energy',\n",
    "                  'Internal_energy_at_0K',\n",
    "                  'Internal_energy_at_298.15K',\n",
    "                  'Enthalpy_at_298.15K',\n",
    "                  'Free_energy_at_298.15K',\n",
    "                  'Heat_capacity_at_298.15K',\n",
    "                  'Atomization_energy_at_0K',\n",
    "                  'Atomization_energy_at_298.15K',\n",
    "                  'Atomization_enthalpy_at_298.15K',\n",
    "                  'Atomization_free_energy_at_298.15K',\n",
    "                  'Rotational_constant_A',\n",
    "                  'Rotational_constant_B',\n",
    "                  'Rotational_constant_C']\n",
    "\n",
    "parameters = {}\n",
    "parameters['tr_batch_size'] = tr_batch_size\n",
    "\n",
    "parameters_used = {}\n",
    "parameters_used['dataset'] = dataset\n",
    "parameters_used['tr_batch_size'] = tr_batch_size\n",
    "parameters_used['val_batch_size'] = val_batch_size\n",
    "parameters_used['test_batch_size'] = test_batch_size\n",
    "parameters_used['tr_ratio'] = tr_ratio\n",
    "parameters_used['val_ratio'] = val_ratio\n",
    "parameters_used['test_ratio'] = test_ratio\n",
    "parameters_used['num_workers'] = num_workers\n",
    "parameters_used['shuffle'] = shuffle\n",
    "parameters_used['target_properties'] = qm9_index_list\n",
    "\n",
    "#vicreg loss function parameters\n",
    "sim_coeff = 25\n",
    "std_coeff = 25\n",
    "cov_coeff = 1\n",
    "\n",
    "#list of training augmentations\n",
    "tr_augmentations = [#A.RWSampling(num_seeds=1000, walk_length=10),\n",
    "                      A.NodeDropping(pn=0.1),\n",
    "                      A.FeatureMasking(pf=0.1),\n",
    "                      A_alternate.EdgeRemoving(pe=0.1)]\n",
    "\n",
    "#list of validation augmentations\n",
    "val_augmentations = []\n",
    "\n",
    "#list of test augmentations\n",
    "test_augmentations = []\n",
    "\n",
    "#number of choices for augmentations for training, validation, and test sets, respectively\n",
    "tr_num_choices = 1\n",
    "val_num_choices = 0\n",
    "test_num_choices = 0\n",
    "\n",
    "#Adam parameters\n",
    "Adam_learning_rate = 0.002\n",
    "Adam_weight_decay = 5e-4\n",
    "adam = {'lr': Adam_learning_rate, \n",
    "        'weight_decay': Adam_weight_decay\n",
    "       }\n",
    "\n",
    "#dictionary of optimizers used\n",
    "optimizers = {}\n",
    "optimizers['adam'] = adam\n",
    "\n",
    "\n",
    "\n",
    "#dictionary of loss functions used\n",
    "loss_functions_used = {}\n",
    "\n",
    "vicreg = {'sim_coeff': sim_coeff,\n",
    "          'std_coeff': std_coeff,\n",
    "          'cov_coeff': cov_coeff\n",
    "         }\n",
    "\n",
    "loss_functions_used['vicreg'] = vicreg\n",
    "\n",
    "augmentations_used = {}\n",
    "augmentations_used['tr_augmentations'] = tr_augmentations\n",
    "augmentations_used['val_augmentations'] = val_augmentations\n",
    "augmentations_used['test_augmentations'] = test_augmentations\n",
    "augmentations_used['tr_num_choices'] = tr_num_choices\n",
    "augmentations_used['val_num_choices'] = val_num_choices\n",
    "augmentations_used['test_num_choices'] = test_num_choices\n",
    "\n",
    "\n",
    "periodic_table = Chem.GetPeriodicTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee7d479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for downstream ML models\n",
    "\n",
    "#dictionary of parameters used for downstream Linear Models\n",
    "lm_parameters = {'default': 'used default for all parameters'}\n",
    "\n",
    "#dictionary of parameters used for downstream Random Forest models\n",
    "rf_parameters = {'n_estimators': 10, \n",
    "                 'max_depth': 10 }\n",
    "\n",
    "#dictionary of parameters used for downstream LightGBM models\n",
    "lgbm_params = {'boosting_type': 'gbdt',\n",
    "               'objective': 'regression',\n",
    "               'metric': {'l2', 'l1'},\n",
    "               'num_leaves': 31,\n",
    "               'learning_rate': 0.05,\n",
    "               'force_col_wise': 'true',\n",
    "               'feature_fraction': 0.9,\n",
    "               'bagging_fraction': 0.8,\n",
    "               'bagging_freq': 5,\n",
    "               'verbose': -1\n",
    "            }\n",
    "lgbm_parameters = {'params': lgbm_params,\n",
    "            'num_boost_round': 20,\n",
    "            'callbacks': [lgb.early_stopping(stopping_rounds=5)]\n",
    "                  }\n",
    "\n",
    "\n",
    "downstream_model_parameters = {}\n",
    "downstream_model_parameters['lm_parameters'] = lm_parameters\n",
    "downstream_model_parameters['rf_parameters'] = rf_parameters\n",
    "downstream_model_parameters['lgbm_parameters'] = lgbm_parameters\n",
    "\n",
    "\n",
    "\n",
    "parameters_used['loss_functions_used'] = loss_functions_used\n",
    "parameters_used['augmentations_used'] = augmentations_used\n",
    "parameters_used['optimizer'] = optimizers\n",
    "parameters_used['adam_learning_rate'] = Adam_learning_rate\n",
    "parameters_used['adam_weight_decay'] = Adam_weight_decay\n",
    "parameters_used['downstream_model_parameters'] = downstream_model_parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa936b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set:  117747\n",
      "Size of validation set:  11774\n",
      "Size of test set:  1310\n"
     ]
    }
   ],
   "source": [
    "#load the dataset through tr, val, and test data loaders\n",
    "\n",
    "whole_dataset = QM9(root = 'data/')\n",
    "\n",
    "n = whole_dataset.len()\n",
    "tr_n = math.floor(tr_ratio*n) # Number of QM9 to use as training data\n",
    "val_n = math.floor(val_ratio*n)\n",
    "\n",
    "\n",
    "all_inds = range(n)\n",
    "tr_inds, val_inds = train_test_split(all_inds, train_size = tr_n, random_state = 24)\n",
    "val_test_inds = range(n - tr_n)\n",
    "val_inds, test_inds = train_test_split(val_test_inds, train_size = val_n, random_state = 24)\n",
    "\n",
    "\n",
    "print(\"Size of training set: \", len(tr_inds))\n",
    "print(\"Size of validation set: \", len(val_inds))\n",
    "print(\"Size of test set: \", len(test_inds))\n",
    "\n",
    "\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(tr_inds)\n",
    "val_sampler = torch.utils.data.SubsetRandomSampler(val_inds)\n",
    "test_sampler = torch.utils.data.SubsetRandomSampler(test_inds)\n",
    "\n",
    "\n",
    "# We need to make a train and validation set since QM9 does not provide them\n",
    "train_set = torch.utils.data.Subset(whole_dataset, tr_inds)\n",
    "val_set = torch.utils.data.Subset(whole_dataset, val_inds)\n",
    "test_set = torch.utils.data.Subset(whole_dataset, test_inds)\n",
    "\n",
    "train_loader = torch_geometric.loader.DataLoader(train_set, batch_size = tr_batch_size,\n",
    "                                                shuffle = shuffle, num_workers = num_workers)\n",
    "                                                #sampler = train_sampler)\n",
    "\n",
    "val_loader = torch_geometric.loader.DataLoader(val_set, batch_size=val_batch_size,\n",
    "                                            shuffle=shuffle, num_workers=num_workers, drop_last=True)\n",
    "                                              #sampler = val_sampler)\n",
    "test_loader = torch_geometric.loader.DataLoader(test_set, batch_size=test_batch_size,\n",
    "                                            shuffle=shuffle, num_workers=num_workers)\n",
    "                                              #sampler = val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e6dc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca46dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fc22a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def off_diagonal(x):\n",
    "    n, m = x.shape\n",
    "    assert n == m\n",
    "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
    "\n",
    "def VicRegLoss(x, y):\n",
    "    # https://github.com/facebookresearch/vicreg/blob/4e12602fd495af83efd1631fbe82523e6db092e0/main_vicreg.py#L184\n",
    "    # x, y are output of projector(backbone(x and y))\n",
    "    repr_loss = F.mse_loss(x, y)\n",
    "\n",
    "    x = x - x.mean(dim=0)\n",
    "    y = y - y.mean(dim=0)\n",
    "\n",
    "    std_x = torch.sqrt(x.var(dim=0) + 0.0001)\n",
    "    std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
    "    std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
    "\n",
    "    cov_x = (x.T @ x) / (tr_batch_size - 1)\n",
    "    cov_y = (y.T @ y) / (tr_batch_size - 1)\n",
    "    cov_loss = off_diagonal(cov_x).pow_(2).sum().div(\n",
    "        x.shape[1]\n",
    "    ) + off_diagonal(cov_y).pow_(2).sum().div(x.shape[1])\n",
    "    \n",
    "    # self.num_features -> rep_dim?\n",
    "    loss = (\n",
    "        sim_coeff * repr_loss\n",
    "        + std_coeff * std_loss\n",
    "        + cov_coeff * cov_loss\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d49f531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f1c487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5307687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rep_dim = 128\n",
    "        self.emb_dim = 256\n",
    "        \n",
    "        # Data under graph\n",
    "        self.conv1 = GCNConv(whole_dataset.num_node_features, self.rep_dim // 2)\n",
    "        self.bn1 = nn.BatchNorm1d(self.rep_dim // 2)\n",
    "        self.a1 = nn.LeakyReLU(0.02)\n",
    "        \n",
    "        self.conv2 = GCNConv(self.rep_dim // 2, self.rep_dim) # To Rep Space\n",
    "        self.bn2 = nn.BatchNorm1d(self.rep_dim)\n",
    "        \n",
    "        # Projection to representation\n",
    "        self.mpool1 = gnn.global_mean_pool\n",
    "        #self.fc1 = nn.Linear(self.rep_dim, self.rep_dim)\n",
    "        \n",
    "        # Graph 2\n",
    "        self.conv3 = GCNConv(self.rep_dim, self.rep_dim * 2) # To Emb Space\n",
    "        self.bn3 = nn.BatchNorm1d(self.rep_dim * 2)\n",
    "        \n",
    "        # Projection to embedding\n",
    "        self.mpool2 = gnn.global_mean_pool\n",
    "        self.fc2 = nn.Linear(self.emb_dim, self.emb_dim) # Linear to rep?\n",
    "            #might want to get rid of this\n",
    "        \n",
    "    def forward(self, data, binds):\n",
    "        x = data[0].float().to(device)\n",
    "        edge_index = data[1].to(device)\n",
    "        \n",
    "        # Input graph to GConv\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.a1(self.bn1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.bn2(self.conv2(x, edge_index))\n",
    "        \n",
    "        # GConv outputs projected to representation space\n",
    "        #print('before pool: ', x.shape)\n",
    "        x_rep = self.mpool1(x, binds)\n",
    "        #print('pooled: ', x_rep.shape)\n",
    "        \n",
    "        #x_rep = self.fc1(x_rep)\n",
    "        #print('projected: ', x_rep.shape, 'gconv', x.shape)\n",
    "        \n",
    "        x_emb = self.bn3(self.conv3(x, edge_index))\n",
    "        #print('x emb after conv3', x_emb.shape)\n",
    "        x_emb = self.mpool2(x_emb, binds)\n",
    "        #print('after pool', x_emb.shape)\n",
    "        x_emb = self.fc2(x_emb)\n",
    "        #print('after fc2', x_emb.shape)\n",
    "        \n",
    "        return x_rep, x_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bb4b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc5cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99fec89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoms_dictionary(atomic_num):\n",
    "    atomic_symbol = periodic_table.GetElementSymbol(atomic_num)\n",
    "    return atomic_symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a4fcd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mol_dict(batch): #Give a chemical formula\n",
    "\n",
    "        graph_chem_formulae_dictionaries = pd.DataFrame()\n",
    "        if not graph_chem_formulae_dictionaries.empty:\n",
    "            graph_chem_formulae_dictionaries.drop(columns = 'formula')\n",
    "\n",
    "        node_to_graph_indicator = pd.DataFrame(batch.batch).astype(\"int\")\n",
    "        node = pd.DataFrame(batch.x).astype(\"int\")\n",
    "        mol_list = []\n",
    "        j = 0\n",
    "        mol_dict = {}\n",
    "        for i in range(len(batch.z)):\n",
    "                #get a dictionary for each graph that contains chemical formula\n",
    "                    #format for use for XenonPy\n",
    "            if j == int(node_to_graph_indicator.iloc[i]):\n",
    "                    #add this ith atom to to the dictionary for the jth graph\n",
    "                    #atoms_dictionary(atomic_num)\n",
    "                    #call function to add element to molecular dictionary\n",
    "                element = atoms_dictionary(int(node[5].iloc[i]))\n",
    "                if element in mol_dict:\n",
    "                    mol_dict[element] = mol_dict[element] + 1\n",
    "                else:\n",
    "                    mol_dict[element] = 1\n",
    "            else: #need to move to next graph\n",
    "                    #Insert these dictionaries to each row in the df\n",
    "                mol_list.append(mol_dict)\n",
    "                mol_dict = {}\n",
    "                element = atoms_dictionary(int(node[5].iloc[i]))\n",
    "                j += 1\n",
    "\n",
    "        mol_list.append(mol_dict) #need to append the last dict\n",
    "        graph_chem_formulae_dictionaries.insert(0, 'formula', mol_list)\n",
    "        for i in range(len(batch.y) - 1):\n",
    "            if mol_list[i]:\n",
    "                pass\n",
    "            else:\n",
    "                print(\"Empty!!\", \" location: \", i)\n",
    "\n",
    "        return graph_chem_formulae_dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a76078cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(loss_per_epoch, val_loss):\n",
    "    train_values = loss_per_epoch\n",
    "    val_values = val_loss\n",
    " \n",
    "    # Generate a sequence of integers to represent the epoch numbers\n",
    "    epochs = range(0, len(loss_per_epoch))\n",
    " \n",
    "    # Plot and label the training and validation loss values\n",
    "    plt.plot(epochs, train_values, label='Training Loss')\n",
    "    plt.plot(epochs, val_values, label='Validation Loss')\n",
    " \n",
    "    # Add in a title and axes labels\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    " \n",
    "    # Set the tick locations\n",
    "\n",
    "    plt.xticks(arange(0, len(loss_per_epoch), max(math.floor(len(loss_per_epoch)/10), 1)))\n",
    " \n",
    "    # Display the plot\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45c70f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50798953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62495a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = GCN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0e354e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentations and optimizers initializations\n",
    "tr_aug = A.RandomChoice(tr_augmentations, #edge_adj was deprecated, so need to use edge_ something instead\n",
    "                      num_choices=tr_num_choices)\n",
    "#should do many other types of augmentations\n",
    "    #train models on all but one augmentations and see which work best\n",
    "        #ablation study!\n",
    "val_aug = A.RandomChoice(val_augmentations, num_choices = val_num_choices)\n",
    "test_aug = A.RandomChoice(test_augmentations, num_choices = test_num_choices)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=Adam_learning_rate, weight_decay=Adam_weight_decay)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be3230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f882d7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3d7dff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "epoch 0 train loss: 19.601951502137265\n",
      "epoch 0 val loss: 16.236791742259058\n",
      "epoch 1 train loss: 25.890916016142246\n",
      "epoch 1 val loss: 17.477760545138654\n",
      "Done training GCL model!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_epochs = 1\n",
    "epoch_loss = []\n",
    "val_epoch_loss = []\n",
    "print(\"Starting Training!\")\n",
    "for epoch in range(0,n_epochs+1):\n",
    "    #print(\"epoch: \", epoch)\n",
    "    epoch_losses = []\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_inds = batch.batch.to(device)\n",
    "      \n",
    "        # batch of graphs has edge attribs, node attribs - (n_nodes, n_features+1) -> concat (n_nodes, attrib1)\n",
    "\n",
    "        batch.x = batch.x.float()#.to(device)\n",
    "        #batch.edge_index = batch.edge_index.to(device)\n",
    "\n",
    "        # Barlow - get 2 random views of batch\n",
    "        b1 = tr_aug(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        b2 = tr_aug(batch.x, batch.edge_index, batch.edge_attr)\n",
    "\n",
    "        # Embed each batch (ignoring representations)\n",
    "        r1, e1 = model(b1, batch_inds)\n",
    "        r2, e2 = model(b2, batch_inds)\n",
    "\n",
    "        loss = VicRegLoss(e1, e2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses.append(loss.data.item())\n",
    "        \n",
    "    epoch_loss.append(sum(epoch_losses) / len(epoch_losses))\n",
    "    print('epoch', epoch,'train loss:', sum(epoch_losses) / len(epoch_losses))\n",
    "\n",
    "    \n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    \n",
    "    # VicReg Validation Loss\n",
    "    val_epoch_losses = []\n",
    "    for batch in val_loader:\n",
    "        with torch.no_grad():\n",
    "            # VicReg validation loss\n",
    "            b1 = val_aug(batch.x, batch.edge_index, batch.edge_attr)\n",
    "            b2 = val_aug(batch.x, batch.edge_index, batch.edge_attr)\n",
    "            r1, e1 = model(b1, batch.batch.to(device))\n",
    "            r2, e2 = model(b2, batch.batch.to(device))\n",
    "                \n",
    "            val_loss = VicRegLoss(e1, e2)\n",
    "            val_epoch_losses.append(val_loss.data.item())\n",
    "            \n",
    "\n",
    "    val_epoch_loss.append(sum(val_epoch_losses) / len(val_epoch_losses))    \n",
    "    print('epoch', epoch,'val loss:', sum(val_epoch_losses) / len(val_epoch_losses))\n",
    "\n",
    "    \n",
    "print(\"Done training GCL model!\")        \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a409dd59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd900cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot train-val loss curves\n",
    "plot_loss_curves(epoch_loss, val_epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef83d662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b32018a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to embed data\n",
    "def get_embeddings(data_loader, model, aug):\n",
    "    x = pd.DataFrame()\n",
    "    x_no_aug = pd.DataFrame()\n",
    "    y = pd.DataFrame()\n",
    "    y_no_aug = pd.DataFrame()\n",
    "    graph_chem_formulae_dictionaries = pd.DataFrame()\n",
    "    for batch in data_loader: # take entire train set\n",
    "        x_tabular_no_aug = pd.DataFrame(batch.x).astype(\"float\")\n",
    "        x_no_aug = pd.concat([x_no_aug, x_tabular_no_aug], ignore_index = True)\n",
    "        y_tabular_no_aug = pd.DataFrame(batch.y).astype(\"float\")\n",
    "        y_no_aug = pd.concat([y_no_aug, y_tabular_no_aug], ignore_index = True)\n",
    "        graph_chem_formulae_dictionaries = pd.concat([graph_chem_formulae_dictionaries, get_mol_dict(batch)], ignore_index = True)\n",
    "        with torch.no_grad():\n",
    "            # Embed training set under model\n",
    "            rep, _ = model(aug(batch.x, batch.edge_index, batch.edge_attr), batch.batch.to(device))\n",
    "            if torch.cuda.is_available():\n",
    "                rep = rep.to(\"cpu\")\n",
    "            rep_tabular = pd.DataFrame(rep.numpy())\n",
    "            x = pd.concat([x, rep_tabular], ignore_index = True)\n",
    "            y_tabular = pd.DataFrame(batch.y).astype(\"float\")\n",
    "            y = pd.concat([y, y_tabular], ignore_index = True)\n",
    "    \n",
    "    return x, y, graph_chem_formulae_dictionaries, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9ec2250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_XenonPy_transform(tr_graph_chem_dict, val_graph_chem_dict, test_graph_chem_dict, col_name):\n",
    "    #returns XenonPy transformations for tr, val, and test sets\n",
    "    print(\"XenonPy transformation starting for training set!\")\n",
    "    xenonpy_obj = XPy.XenonPy_transformation(tr_graph_chem_dict, col_name)\n",
    "    tr_df_XenonPy = xenonpy_obj.XenonPy_transform()\n",
    "    print(\"Done with training set!\")\n",
    "    print(\"XenonPy transformation starting for validation set!\")\n",
    "    xenonpy_obj = XPy.XenonPy_transformation(val_graph_chem_dict, col_name)\n",
    "    val_df_XenonPy = xenonpy_obj.XenonPy_transform()\n",
    "    print(\"Done with validation set!\")\n",
    "    print(\"XenonPy transformation starting for test set!\")\n",
    "    xenonpy_obj = XPy.XenonPy_transformation(test_graph_chem_dict, col_name)\n",
    "    test_df_XenonPy = xenonpy_obj.XenonPy_transform()\n",
    "    print(\"Done with test set!!!!\")\n",
    "    \n",
    "    return tr_df_XenonPy, val_df_XenonPy, test_df_XenonPy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9cd93d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_xenonpy_transformation(tr_df, val_df, test_df, dataset_name): #saves xenonpy transformation to folder\n",
    "    #only do this once per database!!\n",
    "    #filename should be the name of the database\n",
    "    parent_dir = '/home/ewvertina/Molecular_modelling'\n",
    "    new_folder = dataset_name\n",
    "    path = os.path.join(parent_dir, new_folder)\n",
    "    os.mkdir(path)\n",
    "    tr_path = path + '/xenon_tr.csv'\n",
    "    val_path = path + '/xenon_val.csv'\n",
    "    test_path = path + '/xenon_test.csv'\n",
    "    tr_df.to_csv(tr_path)  \n",
    "    val_df.to_csv(val_path)\n",
    "    test_df.to_csv(test_path)\n",
    "    return print(\"XenonPy transformations saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7d94ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get embeddings for training set\n",
    "x_tr, y_tr, tr_graph_chem_formulae_dictionaries, model = get_embeddings(train_loader, model, tr_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5b818d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get embeddings for validation set\n",
    "x_val, y_val, val_graph_chem_formulae_dictionaries, model = get_embeddings(val_loader, model, val_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "949b5048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get embeddings for test set\n",
    "x_test, y_test, test_graph_chem_formulae_dictionaries, model = get_embeddings(test_loader, model, test_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c199ad45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f40f1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6de54630",
   "metadata": {},
   "outputs": [],
   "source": [
    "## transforms tr, val, and test sets with XenonPy and saves to local system\n",
    "#col_name = 'formula'\n",
    "#tr_df_XenonPy, val_df_XenonPy, test_df_XenonPy = get_XenonPy_transform(tr_graph_chem_formulae_dictionaries, val_graph_chem_formulae_dictionaries, test_graph_chem_formulae_dictionaries, col_name)                    \n",
    "#save_xenonpy_transformation(tr_df_XenonPy, val_df_XenonPy, test_df_XenonPy, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99766bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a88c66b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6808e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_models(x_train, x_test, y_train, y_test, target_feature, list_target_features):\n",
    "    lm = LinearRegression().fit(x_train.values, y_train[target_feature].values)\n",
    "    lm_yhat = lm.predict(x_test.values)\n",
    "    lm_score = round(mean_squared_error(y_test[target_feature].values, lm_yhat), 2)\n",
    "    print(\"Linear Regression Model MSE for \", target_feature, \": \", lm_score)\n",
    "    r2 = round(r2_score(y_test[target_feature].values, lm_yhat), 2)\n",
    "    print(\"R^2 score for linear model: \", r2)\n",
    "    \n",
    "    return lm_score, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "30e7a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_models(x_train, x_test, y_train, y_test, target_feature, params, list_target_features):\n",
    "    rf = RandomForestRegressor(n_estimators=params['n_estimators'], max_depth=params['max_depth'])\n",
    "    rf.fit(x_train, y_train[target_feature])\n",
    "    rf_yhat = rf.predict(x_test)\n",
    "    rf_score = round(mean_squared_error(y_test[target_feature], rf_yhat), 2)\n",
    "    print(\"RF Model Mean-Squared-Error for \", target_feature, \": \", rf_score)\n",
    "\n",
    "    return rf_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b4706afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_models(x_train, x_test, y_train, y_test, target_feature, params, list_target_features):\n",
    "    lgb_train = lgb.Dataset(x_train.values, y_train[target_feature].values, params={'verbose': -1})\n",
    "    lgb_eval = lgb.Dataset(x_test.values, y_test[target_feature].values, reference=lgb_train, params={'verbose': -1})\n",
    "    gbm = lgb.train(params['params'],\n",
    "                    lgb_train,\n",
    "                    num_boost_round=params['num_boost_round'],\n",
    "                    valid_sets=lgb_eval,\n",
    "                    callbacks=params['callbacks'])\n",
    "    lgb_yhat = gbm.predict(x_test.values, num_iteration=gbm.best_iteration)\n",
    "    lgb_score = round(mean_squared_error(y_test[target_feature].values, lgb_yhat), 2)\n",
    "    print(\"LightGBM Model MSE for \", target_feature, \": \", lgb_score)\n",
    "\n",
    "    return lgb_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21297cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4abc8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3177b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function to run linear models\n",
    "def linear_models(x_train, x_test, y_train, y_test, list_target_features, rf_parameters, lgbm_params):\n",
    "    # For each task in QM9\n",
    "    results_list = [] #list of dictionaries, where each dictionary contains the results from that model for each feature\n",
    "    lgb_results_dict = {}\n",
    "    rf_results_dict = {}\n",
    "    lm_results_dict = {}\n",
    "    model_info = {}\n",
    "    means_vector = y_train.mean(axis = 0)\n",
    "    rep_means_vectors = means_vector.repeat(x_train.shape[0]) #create a vector where each entry is the mean\n",
    "\n",
    "    for (_, target_feature) in enumerate(y_train):\n",
    "        print(\"target_feature: \", target_feature)\n",
    "        if target_feature == 'index':\n",
    "            pass\n",
    "        else:\n",
    "            ## Fit a model on model representation of train set:\n",
    "            ##Need to drop missing values for linear models, since they do not allow these\n",
    "            lm_score, r2 = lm_models(x_train, x_test, y_train, y_test, target_feature, list_target_features,)\n",
    "            lm_results_dict[\"LM_\" + target_feature] = [lm_score, r2]\n",
    "\n",
    "            #Fit Random Forest models here:\n",
    "            #rf_score = rf_models(x_train, x_test, y_train, y_test, target_feature, rf_parameters, list_target_features)\n",
    "            #rf_results_dict[\"RF_\" + qm9_index_list[target_feature]] = rf_score\n",
    "\n",
    "\n",
    "            #Fit LightGBM models here (LightGBM is supposedly better than XGBoost):\n",
    "            lgb_score = lgbm_models(x_train, x_test, y_train, y_test, target_feature, lgbm_params, list_target_features)\n",
    "            lgb_results_dict[\"Light_GBM_\" + target_feature] = lgb_score\n",
    "\n",
    "\n",
    "\n",
    "            #baseline is a model that always outputs the mean of the training sample        \n",
    "            rep_means_vectors = means_vector[target_feature].repeat(x_test.shape[0])\n",
    "            baseline = round(mean_squared_error(y_test[target_feature].values, rep_means_vectors), 2)\n",
    "            print(\"Baseline MSE for \", target_feature, \": \", baseline)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    results_list.append(lm_results_dict) #append Linear Model results dictionary to results list    \n",
    "    results_list.append(lgb_results_dict) #append Light GBM results dictionary to results list\n",
    "    #results_list.append(rf_results_dict) #append Random Forest results dictionary to results list\n",
    "    \n",
    "    \n",
    "    return results_list, model_info\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cde40c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to make sure that I am getting the correct graphs for y's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9ccf5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join XenonPy transformations with x_tr and x_val\n",
    "#need to access file from saved location\n",
    "#x_tr.join(tr_df_XenonPy)\n",
    "#x_val.join(val_df_XenonPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e27a7a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qm9_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd592e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac14366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qm9_preprocessing(x_df, y_df, qm9_index):\n",
    "    #need to drop the two rows with extremely large Rotational Constant A\n",
    "    y_df.rename(columns=qm9_index, inplace=True)\n",
    "    indexes = y_df.index[(y_df[\"Rotational_constant_A\"] > 100000)]\n",
    "    y_df.drop(y_df.index[indexes], axis=0, inplace=True)\n",
    "    x_df.drop(labels=indexes, axis=0, inplace=True)\n",
    "    y_df = y_df.reset_index()\n",
    "    x_df = x_df.reset_index()\n",
    "    return x_df, y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474bf0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1423b880",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, y_tr = qm9_preprocessing( x_tr, y_tr, qm9_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90ba947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = qm9_preprocessing(x_val, y_val, qm9_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53766709",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = qm9_preprocessing(x_test, y_test, qm9_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ceacc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8f91d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_tr = x_tr.drop(index=[83501, 56941])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e6fd975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_extreme_values(df):\n",
    "    \n",
    "    for column in range(df.shape[1]):\n",
    "        sorted_index_array = np.argsort(df[column])\n",
    "        sorted_array = df[column][sorted_index_array]\n",
    "        n = 10\n",
    "\n",
    "        # find n largest value\n",
    "        max_rslt = sorted_array[-n : ]\n",
    "        min_rslt = sorted_array[ : n]\n",
    "        #print(rslt)\n",
    "        # show the output\n",
    "        print(qm9_index_list[column], \"max values:\\n\", max_rslt)\n",
    "        print(qm9_index_list[column], \"min values:\\n\", min_rslt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "050e7774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "868cf25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_extreme_values(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d55d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_extreme_values(x_val) #need to do this before transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b57aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99d75e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_tr = pd.concat([x_tr, x_val]) #tr and val combined for training set\n",
    "#y_tr = pd.concat([y_tr, y_val]) #tr and val combined for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bbbf5b47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_feature:  index\n",
      "target_feature:  Dipole_moment\n",
      "Linear Regression Model MSE for  Dipole_moment :  1.33\n",
      "R^2 score for linear model:  0.31\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.329152\tvalid_0's l1: 0.424506\n",
      "LightGBM Model MSE for  Dipole_moment :  1.29\n",
      "Baseline MSE for  Dipole_moment :  1.95\n",
      "target_feature:  Isotropic_polarizability\n",
      "Linear Regression Model MSE for  Isotropic_polarizability :  130.89\n",
      "R^2 score for linear model:  -0.65\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.329152\tvalid_0's l1: 0.424506\n",
      "LightGBM Model MSE for  Isotropic_polarizability :  139.32\n",
      "Baseline MSE for  Isotropic_polarizability :  173.16\n",
      "target_feature:  HOMO\n",
      "Linear Regression Model MSE for  HOMO :  0.21\n",
      "R^2 score for linear model:  0.5\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.329152\tvalid_0's l1: 0.424506\n",
      "LightGBM Model MSE for  HOMO :  0.33\n",
      "Baseline MSE for  HOMO :  0.45\n",
      "target_feature:  LUMO\n",
      "Linear Regression Model MSE for  LUMO :  0.54\n",
      "R^2 score for linear model:  0.7\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.329152\tvalid_0's l1: 0.424506\n",
      "LightGBM Model MSE for  LUMO :  0.88\n",
      "Baseline MSE for  LUMO :  1.78\n",
      "target_feature:  HOMO_LUMO_gap\n",
      "Linear Regression Model MSE for  HOMO_LUMO_gap :  0.74\n",
      "R^2 score for linear model:  0.59\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.329152\tvalid_0's l1: 0.424506\n",
      "LightGBM Model MSE for  HOMO_LUMO_gap :  1.01\n",
      "Baseline MSE for  HOMO_LUMO_gap :  1.84\n",
      "target_feature:  Electronic_spatial_extent\n",
      "Linear Regression Model MSE for  Electronic_spatial_extent :  115953.87\n",
      "R^2 score for linear model:  -0.89\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.329152\tvalid_0's l1: 0.424506\n",
      "LightGBM Model MSE for  Electronic_spatial_extent :  110102.54\n",
      "Baseline MSE for  Electronic_spatial_extent :  109581.92\n",
      "target_feature:  Zero_point_vibrational_energy\n",
      "Linear Regression Model MSE for  Zero_point_vibrational_energy :  0.43\n",
      "R^2 score for linear model:  0.51\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.329152\tvalid_0's l1: 0.424506\n",
      "LightGBM Model MSE for  Zero_point_vibrational_energy :  0.51\n",
      "Baseline MSE for  Zero_point_vibrational_energy :  1.06\n",
      "target_feature:  Internal_energy_at_0K\n",
      "Linear Regression Model MSE for  Internal_energy_at_0K :  2937792.81\n",
      "R^2 score for linear model:  -1.01\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.329152\tvalid_0's l1: 0.424506\n",
      "LightGBM Model MSE for  Internal_energy_at_0K :  2621599.59\n",
      "Baseline MSE for  Internal_energy_at_0K :  3296226.11\n",
      "target_feature:  Internal_energy_at_298.15K\n",
      "Linear Regression Model MSE for  Internal_energy_at_298.15K :  2937680.72\n",
      "R^2 score for linear model:  -1.01\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.329152\tvalid_0's l1: 0.424506\n",
      "LightGBM Model MSE for  Internal_energy_at_298.15K :  2621523.8\n",
      "Baseline MSE for  Internal_energy_at_298.15K :  3296154.44\n",
      "target_feature:  Enthalpy_at_298.15K\n",
      "Linear Regression Model MSE for  Enthalpy_at_298.15K :  2937680.69\n",
      "R^2 score for linear model:  -1.01\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.329152\tvalid_0's l1: 0.424506\n",
      "LightGBM Model MSE for  Enthalpy_at_298.15K :  2621523.76\n",
      "Baseline MSE for  Enthalpy_at_298.15K :  3296154.38\n",
      "target_feature:  Free_energy_at_298.15K\n",
      "Linear Regression Model MSE for  Free_energy_at_298.15K :  2937965.16\n",
      "R^2 score for linear model:  -1.01\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.329152\tvalid_0's l1: 0.424506\n",
      "LightGBM Model MSE for  Free_energy_at_298.15K :  2621720.93\n",
      "Baseline MSE for  Free_energy_at_298.15K :  3296351.66\n",
      "target_feature:  Heat_capacity_at_298.15K\n",
      "Linear Regression Model MSE for  Heat_capacity_at_298.15K :  26.57\n",
      "R^2 score for linear model:  -0.31\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.329152\tvalid_0's l1: 0.424506\n",
      "LightGBM Model MSE for  Heat_capacity_at_298.15K :  24.29\n",
      "Baseline MSE for  Heat_capacity_at_298.15K :  30.05\n",
      "target_feature:  Atomization_energy_at_0K\n",
      "Linear Regression Model MSE for  Atomization_energy_at_0K :  135.14\n",
      "R^2 score for linear model:  -0.12\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.329152\tvalid_0's l1: 0.424506\n",
      "LightGBM Model MSE for  Atomization_energy_at_0K :  141.87\n",
      "Baseline MSE for  Atomization_energy_at_0K :  201.29\n",
      "target_feature:  Atomization_energy_at_298.15K\n",
      "Linear Regression Model MSE for  Atomization_energy_at_298.15K :  136.85\n",
      "R^2 score for linear model:  -0.11\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.329152\tvalid_0's l1: 0.424506\n",
      "LightGBM Model MSE for  Atomization_energy_at_298.15K :  143.95\n",
      "Baseline MSE for  Atomization_energy_at_298.15K :  204.39\n",
      "target_feature:  Atomization_enthalpy_at_298.15K\n",
      "Linear Regression Model MSE for  Atomization_enthalpy_at_298.15K :  138.51\n",
      "R^2 score for linear model:  -0.11\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.329152\tvalid_0's l1: 0.424506\n",
      "LightGBM Model MSE for  Atomization_enthalpy_at_298.15K :  145.94\n",
      "Baseline MSE for  Atomization_enthalpy_at_298.15K :  207.05\n",
      "target_feature:  Atomization_free_energy_at_298.15K\n",
      "Linear Regression Model MSE for  Atomization_free_energy_at_298.15K :  115.31\n",
      "R^2 score for linear model:  -0.13\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.329152\tvalid_0's l1: 0.424506\n",
      "LightGBM Model MSE for  Atomization_free_energy_at_298.15K :  121.15\n",
      "Baseline MSE for  Atomization_free_energy_at_298.15K :  171.11\n",
      "target_feature:  Rotational_constant_A\n",
      "Linear Regression Model MSE for  Rotational_constant_A :  26.19\n",
      "R^2 score for linear model:  -0.07\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.329152\tvalid_0's l1: 0.424506\n",
      "LightGBM Model MSE for  Rotational_constant_A :  20.76\n",
      "Baseline MSE for  Rotational_constant_A :  27.07\n",
      "target_feature:  Rotational_constant_B\n",
      "Linear Regression Model MSE for  Rotational_constant_B :  19.15\n",
      "R^2 score for linear model:  0.0\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.329152\tvalid_0's l1: 0.424506\n",
      "LightGBM Model MSE for  Rotational_constant_B :  18.09\n",
      "Baseline MSE for  Rotational_constant_B :  19.43\n",
      "target_feature:  Rotational_constant_C\n",
      "Linear Regression Model MSE for  Rotational_constant_C :  18.87\n",
      "R^2 score for linear model:  0.0\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.329152\tvalid_0's l1: 0.424506\n",
      "LightGBM Model MSE for  Rotational_constant_C :  17.84\n",
      "Baseline MSE for  Rotational_constant_C :  19.09\n"
     ]
    }
   ],
   "source": [
    "results_list, model_info = linear_models(x_tr, x_test, y_tr, y_test, qm9_index_list, rf_parameters, lgbm_parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4911fc9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d95f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_models(x_tr_no_aug, x_val_no_aug, y_tr_no_aug, y_val_no_aug, qm9_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc76a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5386ce4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96262e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record end time\n",
    "t_1 = timeit.default_timer()\n",
    " \n",
    "# calculate elapsed time\n",
    "elapsed_time = round((t_1 - t_0) , 1)\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "elapsed_time_minutes = round((elapsed_time/60), 2)\n",
    "print(f\"Elapsed time: {elapsed_time_minutes} minutes\")\n",
    "elapsed_time_hours = round((elapsed_time/3600), 2)\n",
    "print(f\"Elapsed time: {elapsed_time_hours} hours\")\n",
    "\n",
    "other_info = {'dataset':dataset, 'hours':elapsed_time_hours, 'minutes':elapsed_time_minutes, 'seconds':elapsed_time}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d020e298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb70c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False\n",
    "if run == True:\n",
    "    print(\"Saved!\")\n",
    "    #save experimental results\n",
    "    current_time = datetime.now()\n",
    "    dt_string = current_time.strftime(\"%Y-%m-%d_%H_%M\")\n",
    "    directory = dt_string\n",
    "    parent_dir = '/home/ewvertina/Molecular_modelling/Experiment_Results/'\n",
    "    path = os.path.join(parent_dir, directory)\n",
    "    os.mkdir(path)\n",
    "    path_state_dict = path + '/state_dict'\n",
    "    path_results_dict = path + '/results_dict.txt'\n",
    "    path_runtime = path + '/runtime.txt'\n",
    "    path_parameters = path + '/parameters_used.txt'\n",
    "    path_fig = path + '/train_test_loss.png'\n",
    "    \n",
    "    #save NN model as a torch dictionary\n",
    "    torch.save(model.state_dict(), path_state_dict)\n",
    "    torch.save(results_dict, path_results_dict)\n",
    "    torch.save(other_info, path_runtime) #save which dataset, runtime\n",
    "    torch.save(parameters_used, path_parameters) #saves all parameters used\n",
    "    plt.savefig(path_fig) #save train-val loss figure\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f0640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c6280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66527be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65cb39f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304940bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23057d75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
