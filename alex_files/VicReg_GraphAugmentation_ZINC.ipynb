{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99509334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu117\n"
     ]
    }
   ],
   "source": [
    "# https://arxiv.org/abs/1610.02415\n",
    "\n",
    "# https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.nn as gnn\n",
    "#print(torch_geometric.__version__)\n",
    "from torch_geometric.datasets import QM9\n",
    "import GCL.augmentors\n",
    "import GCL.augmentors as A\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifierCV, LogisticRegression, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73640a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameters = {}\n",
    "parameters['batch_size'] = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2545b3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 128831\n",
      "<class 'list'> <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "whole_dataset = QM9(root = 'data/')\n",
    "\n",
    "#print(whole_dataset.get_summary())\n",
    "#print(dir(whole_dataset))\n",
    "#print(whole_dataset.len())\n",
    "\n",
    "n = whole_dataset.len()\n",
    "tr_n = 2000 # Number of QM9 to use as training data\n",
    "\n",
    "all_inds = range(n)\n",
    "tr_inds, val_inds = train_test_split(all_inds, train_size = tr_n)\n",
    "print(len(tr_inds), len(val_inds))\n",
    "print(type(tr_inds), type(tr_inds[0]))\n",
    "\n",
    "\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(tr_inds)\n",
    "val_sampler = torch.utils.data.SubsetRandomSampler(val_inds)\n",
    "\n",
    "# We need to make a train and validation set since QM9 does not provide them\n",
    "train_set = torch.utils.data.Subset(whole_dataset, tr_inds)\n",
    "val_set = torch.utils.data.Subset(whole_dataset, val_inds)\n",
    "\n",
    "train_loader = torch_geometric.loader.DataLoader(train_set, batch_size = parameters['batch_size'],\n",
    "                                                shuffle = True, num_workers = 2,)\n",
    "                                                #sampler = train_sampler)\n",
    "\n",
    "val_loader = torch_geometric.loader.DataLoader(val_set, batch_size=2048,\n",
    "                                            shuffle=False, num_workers=2,)\n",
    "                                              #sampler = val_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c6ad2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before pool:  torch.Size([1182, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1182, 128])\n",
      "x emb after conv3 torch.Size([1182, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1182, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1182, 128])\n",
      "x emb after conv3 torch.Size([1182, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1131, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1131, 128])\n",
      "x emb after conv3 torch.Size([1131, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1131, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1131, 128])\n",
      "x emb after conv3 torch.Size([1131, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1160, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1160, 128])\n",
      "x emb after conv3 torch.Size([1160, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1160, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1160, 128])\n",
      "x emb after conv3 torch.Size([1160, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1167, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1167, 128])\n",
      "x emb after conv3 torch.Size([1167, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1167, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1167, 128])\n",
      "x emb after conv3 torch.Size([1167, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1145, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1145, 128])\n",
      "x emb after conv3 torch.Size([1145, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1145, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1145, 128])\n",
      "x emb after conv3 torch.Size([1145, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1174, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1174, 128])\n",
      "x emb after conv3 torch.Size([1174, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1174, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1174, 128])\n",
      "x emb after conv3 torch.Size([1174, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1165, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1165, 128])\n",
      "x emb after conv3 torch.Size([1165, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1165, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1165, 128])\n",
      "x emb after conv3 torch.Size([1165, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1146, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1146, 128])\n",
      "x emb after conv3 torch.Size([1146, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1146, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1146, 128])\n",
      "x emb after conv3 torch.Size([1146, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1184, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1184, 128])\n",
      "x emb after conv3 torch.Size([1184, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1184, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1184, 128])\n",
      "x emb after conv3 torch.Size([1184, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1176, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1176, 128])\n",
      "x emb after conv3 torch.Size([1176, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1176, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1176, 128])\n",
      "x emb after conv3 torch.Size([1176, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1182, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1182, 128])\n",
      "x emb after conv3 torch.Size([1182, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1182, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1182, 128])\n",
      "x emb after conv3 torch.Size([1182, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1117, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1117, 128])\n",
      "x emb after conv3 torch.Size([1117, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1117, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1117, 128])\n",
      "x emb after conv3 torch.Size([1117, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1108, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1108, 128])\n",
      "x emb after conv3 torch.Size([1108, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1108, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1108, 128])\n",
      "x emb after conv3 torch.Size([1108, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1171, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1171, 128])\n",
      "x emb after conv3 torch.Size([1171, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1171, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1171, 128])\n",
      "x emb after conv3 torch.Size([1171, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1155, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1155, 128])\n",
      "x emb after conv3 torch.Size([1155, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1155, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1155, 128])\n",
      "x emb after conv3 torch.Size([1155, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1155, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1155, 128])\n",
      "x emb after conv3 torch.Size([1155, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1155, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1155, 128])\n",
      "x emb after conv3 torch.Size([1155, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1159, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1159, 128])\n",
      "x emb after conv3 torch.Size([1159, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1159, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1159, 128])\n",
      "x emb after conv3 torch.Size([1159, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1143, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1143, 128])\n",
      "x emb after conv3 torch.Size([1143, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1143, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1143, 128])\n",
      "x emb after conv3 torch.Size([1143, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1131, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1131, 128])\n",
      "x emb after conv3 torch.Size([1131, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1131, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1131, 128])\n",
      "x emb after conv3 torch.Size([1131, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1120, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1120, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x emb after conv3 torch.Size([1120, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1120, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1120, 128])\n",
      "x emb after conv3 torch.Size([1120, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1114, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1114, 128])\n",
      "x emb after conv3 torch.Size([1114, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1114, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1114, 128])\n",
      "x emb after conv3 torch.Size([1114, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1141, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1141, 128])\n",
      "x emb after conv3 torch.Size([1141, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1141, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1141, 128])\n",
      "x emb after conv3 torch.Size([1141, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1158, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1158, 128])\n",
      "x emb after conv3 torch.Size([1158, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1158, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1158, 128])\n",
      "x emb after conv3 torch.Size([1158, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1117, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1117, 128])\n",
      "x emb after conv3 torch.Size([1117, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1117, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1117, 128])\n",
      "x emb after conv3 torch.Size([1117, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1135, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1135, 128])\n",
      "x emb after conv3 torch.Size([1135, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1135, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1135, 128])\n",
      "x emb after conv3 torch.Size([1135, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1155, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1155, 128])\n",
      "x emb after conv3 torch.Size([1155, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1155, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1155, 128])\n",
      "x emb after conv3 torch.Size([1155, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1173, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1173, 128])\n",
      "x emb after conv3 torch.Size([1173, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1173, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1173, 128])\n",
      "x emb after conv3 torch.Size([1173, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1203, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1203, 128])\n",
      "x emb after conv3 torch.Size([1203, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1203, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1203, 128])\n",
      "x emb after conv3 torch.Size([1203, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1165, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1165, 128])\n",
      "x emb after conv3 torch.Size([1165, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1165, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1165, 128])\n",
      "x emb after conv3 torch.Size([1165, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1116, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1116, 128])\n",
      "x emb after conv3 torch.Size([1116, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1116, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1116, 128])\n",
      "x emb after conv3 torch.Size([1116, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([1139, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1139, 128])\n",
      "x emb after conv3 torch.Size([1139, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "before pool:  torch.Size([1139, 128])\n",
      "pooled:  torch.Size([64, 128])\n",
      "projected:  torch.Size([64, 128]) gconv torch.Size([1139, 128])\n",
      "x emb after conv3 torch.Size([1139, 256])\n",
      "after pool torch.Size([64, 256])\n",
      "after fc2 torch.Size([64, 256])\n",
      "reps torch.Size([64, 128]) torch.Size([64, 128])\n",
      "embs torch.Size([64, 256]) torch.Size([64, 256])\n",
      "before pool:  torch.Size([290, 128])\n",
      "pooled:  torch.Size([16, 128])\n",
      "projected:  torch.Size([16, 128]) gconv torch.Size([290, 128])\n",
      "x emb after conv3 torch.Size([290, 256])\n",
      "after pool torch.Size([16, 256])\n",
      "after fc2 torch.Size([16, 256])\n",
      "before pool:  torch.Size([290, 128])\n",
      "pooled:  torch.Size([16, 128])\n",
      "projected:  torch.Size([16, 128]) gconv torch.Size([290, 128])\n",
      "x emb after conv3 torch.Size([290, 256])\n",
      "after pool torch.Size([16, 256])\n",
      "after fc2 torch.Size([16, 256])\n",
      "reps torch.Size([16, 128]) torch.Size([16, 128])\n",
      "embs torch.Size([16, 256]) torch.Size([16, 256])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 68\u001b[0m\n\u001b[0;32m     60\u001b[0m model \u001b[38;5;241m=\u001b[39m GCN()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     62\u001b[0m aug \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mRandomChoice([\u001b[38;5;66;03m#A.RWSampling(num_seeds=1000, walk_length=10),\u001b[39;00m\n\u001b[0;32m     63\u001b[0m                       A\u001b[38;5;241m.\u001b[39mNodeDropping(pn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m),\n\u001b[0;32m     64\u001b[0m                       A\u001b[38;5;241m.\u001b[39mFeatureMasking(pf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m),\n\u001b[0;32m     65\u001b[0m                       A\u001b[38;5;241m.\u001b[39mEdgeRemoving(pe\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)],\n\u001b[0;32m     66\u001b[0m                      num_choices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     70\u001b[0m     batch_inds \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;66;03m# batch of graphs has edge attribs, node attribs - (n_nodes, n_features+1) -> concat (n_nodes, attrib1)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rdk\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rdk\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1305\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;66;03m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent_workers:\n\u001b[1;32m-> 1305\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shutdown_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1306\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;66;03m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \n\u001b[0;32m   1310\u001b[0m \u001b[38;5;66;03m# Check if the next sample has already been generated\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rdk\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1430\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1425\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mark_worker_as_unavailable(worker_id, shutdown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;66;03m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[0;32m   1428\u001b[0m     \u001b[38;5;66;03m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;66;03m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[1;32m-> 1430\u001b[0m     \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMP_STATUS_CHECK_INTERVAL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1431\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues:\n\u001b[0;32m   1432\u001b[0m     q\u001b[38;5;241m.\u001b[39mcancel_join_thread()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rdk\\lib\\multiprocessing\\process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_pid \u001b[38;5;241m==\u001b[39m os\u001b[38;5;241m.\u001b[39mgetpid(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a child process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a started process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 149\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_popen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    151\u001b[0m     _children\u001b[38;5;241m.\u001b[39mdiscard(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rdk\\lib\\multiprocessing\\popen_spawn_win32.py:108\u001b[0m, in \u001b[0;36mPopen.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m     msecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m))\n\u001b[1;32m--> 108\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForSingleObject\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsecs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mWAIT_OBJECT_0:\n\u001b[0;32m    110\u001b[0m     code \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mGetExitCodeProcess(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rep_dim = 128\n",
    "        self.emb_dim = 256\n",
    "        \n",
    "        # Data under graph\n",
    "        self.conv1 = GCNConv(whole_dataset.num_node_features, self.rep_dim // 2)\n",
    "        self.bn1 = nn.BatchNorm1d(self.rep_dim // 2)\n",
    "        self.a1 = nn.LeakyReLU(0.02)\n",
    "        \n",
    "        self.conv2 = GCNConv(self.rep_dim // 2, self.rep_dim) # To Rep Space\n",
    "        self.bn2 = nn.BatchNorm1d(self.rep_dim)\n",
    "        \n",
    "        # Projection to representation\n",
    "        self.mpool1 = gnn.global_mean_pool\n",
    "        self.fc1 = nn.Linear(self.rep_dim, self.rep_dim)\n",
    "        \n",
    "        # Graph 2\n",
    "        self.conv3 = GCNConv(self.rep_dim, self.rep_dim * 2) # To Emb Space\n",
    "        self.bn3 = nn.BatchNorm1d(self.rep_dim * 2)\n",
    "        \n",
    "        # Projection to embedding\n",
    "        self.mpool2 = gnn.global_mean_pool\n",
    "        self.fc2 = nn.Linear(self.emb_dim, self.emb_dim) # Linear to rep?\n",
    "        \n",
    "    def forward(self, data, binds):\n",
    "        x = data[0].float().to(device)\n",
    "        edge_index = data[1].to(device)\n",
    "        \n",
    "        # Input graph to GConv\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.a1(self.bn1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.bn2(self.conv2(x, edge_index))\n",
    "        \n",
    "        # GConv outputs projected to representation space\n",
    "        print('before pool: ', x.shape)\n",
    "        x_rep = self.mpool1(x, binds)\n",
    "        print('pooled: ', x_rep.shape)\n",
    "        \n",
    "        x_rep = self.fc1(x_rep)\n",
    "        print('projected: ', x_rep.shape, 'gconv', x.shape)\n",
    "        \n",
    "        x_emb = self.bn3(self.conv3(x, edge_index))\n",
    "        print('x emb after conv3', x_emb.shape)\n",
    "        x_emb = self.mpool2(x_emb, binds)\n",
    "        print('after pool', x_emb.shape)\n",
    "        x_emb = self.fc2(x_emb)\n",
    "        print('after fc2', x_emb.shape)\n",
    "        \n",
    "        return x_rep, x_emb\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "model = GCN().to(device)\n",
    "\n",
    "aug = A.RandomChoice([#A.RWSampling(num_seeds=1000, walk_length=10),\n",
    "                      A.NodeDropping(pn=0.1),\n",
    "                      A.FeatureMasking(pf=0.1),\n",
    "                      A.EdgeRemoving(pe=0.1)],\n",
    "                     num_choices=1)\n",
    "\n",
    "for batch in train_loader:\n",
    "\n",
    "    batch_inds = batch.batch.to(device)\n",
    "    \n",
    "    # batch of graphs has edge attribs, node attribs - (n_nodes, n_features+1) -> concat (n_nodes, attrib1)\n",
    "    \n",
    "    batch.x = batch.x.float()#.to(device)\n",
    "    #batch.edge_index = batch.edge_index.to(device)\n",
    "\n",
    "    # Barlow - get 2 random views of batch\n",
    "    b1 = aug(batch.x, batch.edge_index, batch.edge_attr)\n",
    "    b2 = aug(batch.x, batch.edge_index, batch.edge_attr)\n",
    "    \n",
    "    # Embed each batch (ignoring representations)\n",
    "    r1, e1 = model(b1, batch_inds)\n",
    "    r2, e2 = model(b2, batch_inds)\n",
    "    \n",
    "    \n",
    "    print('reps', r1.shape, r2.shape)\n",
    "    print('embs', e1.shape, e2.shape)\n",
    "    \n",
    "    loss \n",
    "    \n",
    "    \n",
    "    if val_step:\n",
    "        for batch in val_loader:\n",
    "            \n",
    "            rep, _ = model(val_aug(batch.x, batch.edge_index, batch.edge_attr), batch.batch.to(device))\n",
    "            \n",
    "            lm = LinearClassifier(rep, batch.y)\n",
    "            \n",
    "            for tar in tagets:\n",
    "                lm = LinearClassifier(rep, batch.tar)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bb0f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b04aa945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 78\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m     77\u001b[0m     epo_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;66;03m#batch = batch.to(device)\u001b[39;00m\n\u001b[0;32m     80\u001b[0m         batch\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;66;03m#.to(device)\u001b[39;00m\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;66;03m#batch.edge_index = batch.edge_index.to(device)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rdk\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:435\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rdk\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:381\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rdk\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1034\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1027\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1034\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rdk\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rdk\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rdk\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rdk\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rdk\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = GCN().to(device)\n",
    "#data = train_dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "aug = A.RandomChoice([#A.RWSampling(num_seeds=1000, walk_length=10),\n",
    "                      A.NodeDropping(pn=0.1),\n",
    "                      A.FeatureMasking(pf=0.1),\n",
    "                      A.EdgeRemoving(pe=0.1)],\n",
    "                     num_choices=1)\n",
    "\n",
    "val_aug = A.RandomChoice([], num_choices = 0)\n",
    "\n",
    "\n",
    "def barlow(batch):\n",
    "    # Return two random views of input batch\n",
    "    return aug(batch[0], batch[1]), aug(batch[0], batch[1])\n",
    "\n",
    "def off_diagonal(x):\n",
    "    n, m = x.shape\n",
    "    assert n == m\n",
    "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
    "\n",
    "class FullGatherLayer(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Gather tensors from all process and support backward propagation\n",
    "    for the gradients across processes.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        output = [torch.zeros_like(x) for _ in range(dist.get_world_size())]\n",
    "        dist.all_gather(output, x)\n",
    "        return tuple(output)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, *grads):\n",
    "        all_gradients = torch.stack(grads)\n",
    "        dist.all_reduce(all_gradients)\n",
    "        return all_gradients[dist.get_rank()]\n",
    "    \n",
    "def VicRegLoss(x, y):\n",
    "    # https://github.com/facebookresearch/vicreg/blob/4e12602fd495af83efd1631fbe82523e6db092e0/main_vicreg.py#L184\n",
    "    # x, y are output of projector(backbone(x and y))\n",
    "    repr_loss = F.mse_loss(x, y)\n",
    "\n",
    "    x = x - x.mean(dim=0)\n",
    "    y = y - y.mean(dim=0)\n",
    "\n",
    "    std_x = torch.sqrt(x.var(dim=0) + 0.0001)\n",
    "    std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
    "    std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
    "\n",
    "    cov_x = (x.T @ x) / (parameters['batch_size'] - 1)\n",
    "    cov_y = (y.T @ y) / (parameters['batch_size'] - 1)\n",
    "    cov_loss = off_diagonal(cov_x).pow_(2).sum().div(\n",
    "        x.shape[1]\n",
    "    ) + off_diagonal(cov_y).pow_(2).sum().div(x.shape[1])\n",
    "    \n",
    "    # self.num_features -> rep_dim?\n",
    "    loss = (\n",
    "        sim_coeff * repr_loss\n",
    "        + std_coeff * std_loss\n",
    "        + cov_coeff * cov_loss\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "sim_coeff = 25\n",
    "std_coeff = 25\n",
    "cov_coeff = 1\n",
    "\n",
    "model.train()\n",
    "for epoch in range(5):\n",
    "    \n",
    "    epo_losses = []\n",
    "    for batch in train_loader:\n",
    "        #batch = batch.to(device)\n",
    "        batch.x = batch.x.float()#.to(device)\n",
    "        #batch.edge_index = batch.edge_index.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Barlow - get 2 random views of batch\n",
    "        b1 = aug(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        b2 = aug(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        \n",
    "                \n",
    "        # Embed each batch (ignoring representations)\n",
    "        [r1, e1], [r2, e2] = model.pair_emb_rep(b1, b2)\n",
    "\n",
    "        # VicReg loss on projections\n",
    "        loss = VicRegLoss(e1, e2)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epo_losses.append(loss.data.item())\n",
    "        \n",
    "    print(sum(epo_losses) / len(epo_losses))\n",
    "    \n",
    "    ############################\n",
    "    ## Per-epoch validation step:\n",
    "    \n",
    "    GCL.eval\n",
    "\n",
    "\n",
    "    # Embed Training Samples:\n",
    "    train_batch = next(iter(train_big_subset))\n",
    "    #print('train batch', train_batch)\n",
    "    train_batch = val_aug(train_batch.x, train_batch.edge_index, train_batch.edge_attr) # val_aug is an empty augmentation\n",
    "    #print('train_batch augd', train_batch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tr_rep, _ = model.forward(train_batch)\n",
    "    #print(tr_rep.shape)\n",
    "\n",
    "    # Train linear model on embedded samples:\n",
    "    ridge_mod = RidgeClassifierCV(cv = 4).fit(tr_rep, y_train)\n",
    "    linear_mod = LogisticRegression(penalty = None).fit(tr_rep, y_train)\n",
    "\n",
    "    # Embed validation samples:\n",
    "    val_batch = next(iter(val_loader))\n",
    "    #print('val batch', val_batch)\n",
    "    val_batch = val_aug(val_batch.x, val_batch.edge_index, val_batch.edge_attr) # val_aug is an empty augmentation\n",
    "    #print('val_batch augd', val_batch)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_rep, _ = model.forward(val_batch)\n",
    "    #print(val_rep.shape)\n",
    "\n",
    "    # Test linear model on embedded samples:\n",
    "    ridge_score = f1_score(ridge_mod.predict(val_rep), y_val)\n",
    "    linear_score = f1_score(linear_mod.predict(val_rep), y_val)\n",
    "    \n",
    "    print(f'Classifier Scores at Epoch {epoch}:', round(linear_score, 3), round(ridge_score, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93024f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # Update for some downstream? Keep in mind this idea of graph masking\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    pred = model(data).argmax(dim=1)\n",
    "    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "    acc = int(correct) / int(data.test_mask.sum())\n",
    "    print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb308ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca503f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
